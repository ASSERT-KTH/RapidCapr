{
    "patch": "public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n    private static final double TWO_EPS_SQ = 2 * FastMath.sqrt(FastMath.sqrt(Precision.EPSILON));\n\n    /** Levenberg-Marquardt parameter. */\n    private double lmPar;\n\n    /** Parameters evolution direction associated with LM algorithm. */\n    private double[] lmDir;\n\n    /** Diagonal elements of the R matrix in the QR decomposition. */\n    private double[] diagR;\n\n    /** Norms of the columns of the jacobian matrix. */\n    private double[] jacNorm;\n\n    /** Coefficients for the L-M updating formula. */\n    private double[] beta;\n\n    /** Permutation array. */\n    private int[] permutation;\n\n    /** Rank of the jacobian matrix. */\n    private int rank;\n\n    /** Cached QR decomposition. */\n    private QRDecomposition qr = null;\n\n    /**\n     * Constructor with default values.\n     */\n    public LevenbergMarquardtOptimizer() {\n        super(null);\n    }\n\n    /**\n     * @param checker Convergence checker.\n     */\n    public LevenbergMarquardtOptimizer(ConvergenceChecker<Evaluation> checker) {\n        super(checker);\n    }\n\n    /**\n     * Compute the Jacobian matrix.\n     *\n     * @return the Jacobian matrix.\n     * @throws FunctionEvaluationException if the function cannot be evaluated.\n     */\n    protected double[][] computeJacobian() throws FunctionEvaluationException {\n        final MultivariateVectorFunction jf = getModelFunction().gradient();\n        return this.computeJacobian(jf);\n    }\n\n    /**\n     * Compute the Jacobian matrix of a {@link MultivariateVectorFunction}. Rows\n     * are the dimensions of the output and columns are the dimensions of the\n     * input.\n     *\n     * @param f Gradient/vector function to compute Jacobian of\n     * @return the Jacobian matrix\n     */\n    protected double[][] computeJacobian(final MultivariateVectorFunction f) {\n        final int n = observedData.length;\n        final int m = parameters.length;\n        final double[][] jacobian = new double[n][m];\n        for (int i = 0; i < n; ++i) {\n            final double[] grad = f.value(parameters, observedData[i]);\n            if (grad.length != m) {\n                throw new DimensionMismatchException(grad.length, m);\n            }\n            for (int j = 0; j < m; ++j) {\n                jacobian[i][j] = grad[j];\n            }\n        }\n\n        return jacobian;\n    }\n\n    /**\n     * Compute the weighted Jacobian matrix.\n     * @return the weighted Jacobian matrix.\n     * @throws FunctionEvaluationException if the function cannot be evaluated.\n     */\n    protected double[][] computeWeightedJacobian() throws FunctionEvaluationException {\n        final double[][] jacobian = computeJacobian();\n        for (int i = 0; i < rows; ++i) {\n            final double sqrtWeight = FastMath.sqrt(weight[i]);\n            for (int j = 0; j < cols; ++j) {\n                jacobian[i][j] *= sqrtWeight;\n            }\n        }\n        return jacobian;\n    }\n\n    /**\n     * {@inheritDoc}\n     */\n    @Override\n    protected VectorialPointValuePair doOptimize()\n            throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols = FastMath.min(rows, cols);\n        diagR      = new double[cols];\n        jacNorm    = new double[cols];\n        beta       = new double[cols];\n        permutation = new int[cols];\n        lmDir      = new double[cols];\n\n        // local point\n        double[] x     = new double[cols];\n        double[] diag  = new double[cols];\n        double[] oldX  = new double[cols];\n        double[] oldRes= new double[rows];\n        double[] work1 = new double[cols];\n        double[] work2 = new double[cols];\n        double[] work3 = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n        double[] y      = getResiduals();\n        double[] weightedJacobian = computeWeightedJacobian();\n        PointVectorValuePair current =\n            new PointVectorValuePair(getStartPoint(), y);\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        PointVectorValuePair previous = null;\n        while (true) {\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the Jacobian matrix\n            qr = new QRDecomposition(weightedJacobian);\n            weightedJacobian = qr.getR().getData();\n            permutation = qr.getPivot();\n\n            // compute Qt.y\n            qTy(y);\n\n            // now we don't need Q anymore, so let jacobian contain the R matrix with its diagonal elements\n            for (int i = 0; i < solvedCols; ++i) {\n                final int diagIndex = i * (i + 1) / 2;\n                diagR[i] = weightedJacobian[diagIndex];\n                if (diagR[i] == 0.0) {\n                    diagR[i] = qyNorm / TWO_EPS_SQ;\n                }\n            }\n\n            if (checker != null) {\n                if (previous != null) {\n                    double[] currentPoint   = current.getPointRef();\n                    double[] previousPoint  = previous.getPointRef();\n                    boolean converged =\n                        checker.converged(getIterations(), new PointVectorValuePair(currentPoint,\n                                                                                 y),\n                                          new PointVectorValuePair(previousPoint,\n                                                                                 previous.getValuesRef()));\n                    if (converged) {\n                        return current;\n                    }\n                }\n                previous = current;\n            }\n\n            // rescale if necessary\n            // on the first iteration, we rescale always\n            if (firstIteration) {\n                lmDiagonal = new double[diagR.length];\n                for (int i = 0; i < diagR.length; ++i) {\n                    lmDiagonal[i] = diagR[i] == 0 ? 1 : diagR[i];\n                }\n            }\n            determineLMDirection(y);\n            double lmNorm = 0;\n            for (int j = 0; j < cols; ++j) {\n                lmDir[j] = diag[j] * lmDir[j];\n                lmNorm  += lmDir[j] * lmDir[j];\n            }\n            lmNorm = FastMath.sqrt(lmNorm);\n            if (firstIteration) {\n                delta = lmNorm;\n            }\n\n            // normalize LM direction\n            if (lmNorm > delta) {\n                for (int j = 0;j < cols;j++) {\n                    lmDir[j] *= delta / lmNorm;\n                }\n                lmNorm = delta;\n            }\n\n            // set the next test point\n            for (int j = 0;j < cols;j++) {\n                double init = current.getPoint()[j];\n                x[j] = init + lmDir[j];\n            }\n\n            // evaluate the function at x + p and calculate its norm\n            updateResidualsAndCost(x);\n            double[] resNext = getResiduals();\n            PointVectorValuePair next =\n                new PointVectorValuePair(x, resNext);\n            double[] yNext = next.getValuesRef();\n            double[] ws = getWeight();\n            double sumSquares = 0;\n            for (int i = 0; i < ws.length; ++i) {\n                final double ri = yNext[i] * ws[i];\n                sumSquares += ri * ri;\n            }\n            double actRed = -1.0;\n            if (0.1 * sumSquares < cost) {\n                double[] work = new double[cols];\n                for (int j = 0;j < solvedCols;j++) {\n                    work[permutation[j]] = yNext[j];\n                }\n                double sumSquaresNext = 0;\n                for (int i = 0; i < ws.length; ++i) {\n                    final double ri = work[i] * ws[i];\n                    sumSquaresNext += ri * ri;\n                }\n                actRed = (cost - sumSquaresNext) / (0.5 * lmNorm * (lmNorm * rho + beta",
    "patch_diff": "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex 50914932e..68daa9425 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -238,230 +238,227 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n     /** {@inheritDoc} */\n     @Override\n+public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n+    private static final double TWO_EPS_SQ = 2 * FastMath.sqrt(FastMath.sqrt(Precision.EPSILON));\n+\n+    /** Levenberg-Marquardt parameter. */\n+    private double lmPar;\n+\n+    /** Parameters evolution direction associated with LM algorithm. */\n+    private double[] lmDir;\n+\n+    /** Diagonal elements of the R matrix in the QR decomposition. */\n+    private double[] diagR;\n+\n+    /** Norms of the columns of the jacobian matrix. */\n+    private double[] jacNorm;\n+\n+    /** Coefficients for the L-M updating formula. */\n+    private double[] beta;\n+\n+    /** Permutation array. */\n+    private int[] permutation;\n+\n+    /** Rank of the jacobian matrix. */\n+    private int rank;\n+\n+    /** Cached QR decomposition. */\n+    private QRDecomposition qr = null;\n+\n+    /**\n+     * Constructor with default values.\n+     */\n+    public LevenbergMarquardtOptimizer() {\n+        super(null);\n+    }\n+\n+    /**\n+     * @param checker Convergence checker.\n+     */\n+    public LevenbergMarquardtOptimizer(ConvergenceChecker<Evaluation> checker) {\n+        super(checker);\n+    }\n+\n+    /**\n+     * Compute the Jacobian matrix.\n+     *\n+     * @return the Jacobian matrix.\n+     * @throws FunctionEvaluationException if the function cannot be evaluated.\n+     */\n+    protected double[][] computeJacobian() throws FunctionEvaluationException {\n+        final MultivariateVectorFunction jf = getModelFunction().gradient();\n+        return this.computeJacobian(jf);\n+    }\n+\n+    /**\n+     * Compute the Jacobian matrix of a {@link MultivariateVectorFunction}. Rows\n+     * are the dimensions of the output and columns are the dimensions of the\n+     * input.\n+     *\n+     * @param f Gradient/vector function to compute Jacobian of\n+     * @return the Jacobian matrix\n+     */\n+    protected double[][] computeJacobian(final MultivariateVectorFunction f) {\n+        final int n = observedData.length;\n+        final int m = parameters.length;\n+        final double[][] jacobian = new double[n][m];\n+        for (int i = 0; i < n; ++i) {\n+            final double[] grad = f.value(parameters, observedData[i]);\n+            if (grad.length != m) {\n+                throw new DimensionMismatchException(grad.length, m);\n+            }\n+            for (int j = 0; j < m; ++j) {\n+                jacobian[i][j] = grad[j];\n+            }\n+        }\n+\n+        return jacobian;\n+    }\n+\n+    /**\n+     * Compute the weighted Jacobian matrix.\n+     * @return the weighted Jacobian matrix.\n+     * @throws FunctionEvaluationException if the function cannot be evaluated.\n+     */\n+    protected double[][] computeWeightedJacobian() throws FunctionEvaluationException {\n+        final double[][] jacobian = computeJacobian();\n+        for (int i = 0; i < rows; ++i) {\n+            final double sqrtWeight = FastMath.sqrt(weight[i]);\n+            for (int j = 0; j < cols; ++j) {\n+                jacobian[i][j] *= sqrtWeight;\n+            }\n+        }\n+        return jacobian;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n     protected VectorialPointValuePair doOptimize()\n-        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n+            throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n \n         // arrays shared with the other private methods\n-        solvedCols  = Math.min(rows, cols);\n-        diagR       = new double[cols];\n-        jacNorm     = new double[cols];\n-        beta        = new double[cols];\n+        solvedCols = FastMath.min(rows, cols);\n+        diagR      = new double[cols];\n+        jacNorm    = new double[cols];\n+        beta       = new double[cols];\n         permutation = new int[cols];\n-        lmDir       = new double[cols];\n+        lmDir      = new double[cols];\n \n         // local point\n-        double   delta   = 0;\n-        double   xNorm   = 0;\n-        double[] diag    = new double[cols];\n-        double[] oldX    = new double[cols];\n-        double[] oldRes  = new double[rows];\n-        double[] work1   = new double[cols];\n-        double[] work2   = new double[cols];\n-        double[] work3   = new double[cols];\n+        double[] x     = new double[cols];\n+        double[] diag  = new double[cols];\n+        double[] oldX  = new double[cols];\n+        double[] oldRes= new double[rows];\n+        double[] work1 = new double[cols];\n+        double[] work2 = new double[cols];\n+        double[] work3 = new double[cols];\n \n         // evaluate the function at the starting point and calculate its norm\n         updateResidualsAndCost();\n+        double[] y      = getResiduals();\n+        double[] weightedJacobian = computeWeightedJacobian();\n+        PointVectorValuePair current =\n+            new PointVectorValuePair(getStartPoint(), y);\n \n         // outer loop\n         lmPar = 0;\n         boolean firstIteration = true;\n-        VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n+        PointVectorValuePair previous = null;\n         while (true) {\n             incrementIterationsCounter();\n \n-            // compute the Q.R. decomposition of the jacobian matrix\n-            VectorialPointValuePair previous = current;\n-            updateJacobian();\n-            qrDecomposition();\n-\n-            // compute Qt.res\n-            qTy(residuals);\n-            // now we don't need Q anymore,\n-            // so let jacobian contain the R matrix with its diagonal elements\n-            for (int k = 0; k < solvedCols; ++k) {\n-                int pk = permutation[k];\n-                jacobian[k][pk] = diagR[pk];\n-            }\n+            // compute the Q.R. decomposition of the Jacobian matrix\n+            qr = new QRDecomposition(weightedJacobian);\n+            weightedJacobian = qr.getR().getData();\n+            permutation = qr.getPivot();\n \n-            if (firstIteration) {\n+            // compute Qt.y\n+            qTy(y);\n \n-                // scale the point according to the norms of the columns\n-                // of the initial jacobian\n-                xNorm = 0;\n-                for (int k = 0; k < cols; ++k) {\n-                    double dk = jacNorm[k];\n-                    if (dk == 0) {\n-                        dk = 1.0;\n-                    }\n-                    double xk = dk * point[k];\n-                    xNorm  += xk * xk;\n-                    diag[k] = dk;\n+            // now we don't need Q anymore, so let jacobian contain the R matrix with its diagonal elements\n+            for (int i = 0; i < solvedCols; ++i) {\n+                final int diagIndex = i * (i + 1) / 2;\n+                diagR[i] = weightedJacobian[diagIndex];\n+                if (diagR[i] == 0.0) {\n+                    diagR[i] = qyNorm / TWO_EPS_SQ;\n                 }\n-                xNorm = Math.sqrt(xNorm);\n-\n-                // initialize the step bound delta\n-                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n-\n             }\n \n-            // check orthogonality between function vector and jacobian columns\n-            double maxCosine = 0;\n-            if (cost != 0) {\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int    pj = permutation[j];\n-                    double s  = jacNorm[pj];\n-                    if (s != 0) {\n-                        double sum = 0;\n-                        for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * residuals[i];\n-                        }\n-                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n+            if (checker != null) {\n+                if (previous != null) {\n+                    double[] currentPoint   = current.getPointRef();\n+                    double[] previousPoint  = previous.getPointRef();\n+                    boolean converged =\n+                        checker.converged(getIterations(), new PointVectorValuePair(currentPoint,\n+                                                                                 y),\n+                                          new PointVectorValuePair(previousPoint,\n+                                                                                 previous.getValuesRef()));\n+                    if (converged) {\n+                        return current;\n                     }\n                 }\n-            }\n-            if (maxCosine <= orthoTolerance) {\n-                // convergence has been reached\n-                return current;\n+                previous = current;\n             }\n \n             // rescale if necessary\n+            // on the first iteration, we rescale always\n+            if (firstIteration) {\n+                lmDiagonal = new double[diagR.length];\n+                for (int i = 0; i < diagR.length; ++i) {\n+                    lmDiagonal[i] = diagR[i] == 0 ? 1 : diagR[i];\n+                }\n+            }\n+            determineLMDirection(y);\n+            double lmNorm = 0;\n             for (int j = 0; j < cols; ++j) {\n-                diag[j] = Math.max(diag[j], jacNorm[j]);\n+                lmDir[j] = diag[j] * lmDir[j];\n+                lmNorm  += lmDir[j] * lmDir[j];\n+            }\n+            lmNorm = FastMath.sqrt(lmNorm);\n+            if (firstIteration) {\n+                delta = lmNorm;\n             }\n \n-            // inner loop\n-            for (double ratio = 0; ratio < 1.0e-4;) {\n-\n-                // save the state\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    oldX[pj] = point[pj];\n-                }\n-                double previousCost = cost;\n-                double[] tmpVec = residuals;\n-                residuals = oldRes;\n-                oldRes    = tmpVec;\n-\n-                // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n-\n-                // compute the new point and the norm of the evolution direction\n-                double lmNorm = 0;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    lmDir[pj] = -lmDir[pj];\n-                    point[pj] = oldX[pj] + lmDir[pj];\n-                    double s = diag[pj] * lmDir[pj];\n-                    lmNorm  += s * s;\n-                }\n-                lmNorm = Math.sqrt(lmNorm);\n-                // on the first iteration, adjust the initial step bound.\n-                if (firstIteration) {\n-                    delta = Math.min(delta, lmNorm);\n-                }\n-\n-                // evaluate the function at x + p and calculate its norm\n-                updateResidualsAndCost();\n-                current = new VectorialPointValuePair(point, objective);\n-\n-                // compute the scaled actual reduction\n-                double actRed = -1.0;\n-                if (0.1 * cost < previousCost) {\n-                    double r = cost / previousCost;\n-                    actRed = 1.0 - r * r;\n+            // normalize LM direction\n+            if (lmNorm > delta) {\n+                for (int j = 0;j < cols;j++) {\n+                    lmDir[j] *= delta / lmNorm;\n                 }\n+                lmNorm = delta;\n+            }\n \n-                // compute the scaled predicted reduction\n-                // and the scaled directional derivative\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    double dirJ = lmDir[pj];\n-                    work1[j] = 0;\n-                    for (int i = 0; i <= j; ++i) {\n-                        work1[i] += jacobian[i][pj] * dirJ;\n-                    }\n-                }\n-                double coeff1 = 0;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    coeff1 += work1[j] * work1[j];\n-                }\n-                double pc2 = previousCost * previousCost;\n-                coeff1 = coeff1 / pc2;\n-                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n-                double preRed = coeff1 + 2 * coeff2;\n-                double dirDer = -(coeff1 + coeff2);\n-\n-                // ratio of the actual to the predicted reduction\n-                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n-\n-                // update the step bound\n-                if (ratio <= 0.25) {\n-                    double tmp =\n-                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n-                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n-                            tmp = 0.1;\n-                        }\n-                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n-                        lmPar /= tmp;\n-                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n-                    delta = 2 * lmNorm;\n-                    lmPar *= 0.5;\n-                }\n+            // set the next test point\n+            for (int j = 0;j < cols;j++) {\n+                double init = current.getPoint()[j];\n+                x[j] = init + lmDir[j];\n+            }\n \n-                // test for successful iteration.\n-                if (ratio >= 1.0e-4) {\n-                    // successful iteration, update the norm\n-                    firstIteration = false;\n-                    xNorm = 0;\n-                    for (int k = 0; k < cols; ++k) {\n-                        double xK = diag[k] * point[k];\n-                        xNorm    += xK * xK;\n-                    }\n-                    xNorm = Math.sqrt(xNorm);\n-\n-                    // tests for convergence.\n-                    // we use the vectorial convergence checker\n-                } else {\n-                    // failed iteration, reset the previous values\n-                    cost = previousCost;\n-                    for (int j = 0; j < solvedCols; ++j) {\n-                        int pj = permutation[j];\n-                        point[pj] = oldX[pj];\n-                    }\n-                    tmpVec    = residuals;\n-                    residuals = oldRes;\n-                    oldRes    = tmpVec;\n-                }\n-                if (checker==null) {\n-                \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n-                        (preRed <= costRelativeTolerance) &&\n-                        (ratio <= 2.0)) ||\n-                       (delta <= parRelativeTolerance * xNorm)) {\n-                       return current;\n-                   }\n-                } else {\n-                    if (checker.converged(getIterations(), previous, current)) {\n-                        return current;\n-                    }\n+            // evaluate the function at x + p and calculate its norm\n+            updateResidualsAndCost(x);\n+            double[] resNext = getResiduals();\n+            PointVectorValuePair next =\n+                new PointVectorValuePair(x, resNext);\n+            double[] yNext = next.getValuesRef();\n+            double[] ws = getWeight();\n+            double sumSquares = 0;\n+            for (int i = 0; i < ws.length; ++i) {\n+                final double ri = yNext[i] * ws[i];\n+                sumSquares += ri * ri;\n+            }\n+            double actRed = -1.0;\n+            if (0.1 * sumSquares < cost) {\n+                double[] work = new double[cols];\n+                for (int j = 0;j < solvedCols;j++) {\n+                    work[permutation[j]] = yNext[j];\n                 }\n-                // tests for termination and stringent tolerances\n-                // (2.2204e-16 is the machine epsilon for IEEE754)\n-                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n-                            costRelativeTolerance);\n-                } else if (delta <= 2.2204e-16 * xNorm) {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n-                            parRelativeTolerance);\n-                } else if (maxCosine <= 2.2204e-16)  {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n-                            orthoTolerance);\n+                double sumSquaresNext = 0;\n+                for (int i = 0; i < ws.length; ++i) {\n+                    final double ri = work[i] * ws[i];\n+                    sumSquaresNext += ri * ri;\n                 }\n-\n-            }\n-\n-        }\n-\n-    }\n+                actRed = (cost - sumSquaresNext) / (0.5 * lmNorm * (lmNorm * rho + beta\n \n     /**\n      * Determine the Levenberg-Marquardt parameter.",
    "result_reason": "error: ')' expected",
    "test_result": "ERROR"
}