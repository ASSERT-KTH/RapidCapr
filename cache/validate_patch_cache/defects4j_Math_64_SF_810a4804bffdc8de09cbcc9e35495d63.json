{
    "patch": "import org.apache.commons.math3.exception.MathIllegalStateException;\nimport org.apache.commons.math3.exception.TooManyEvaluationsException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.linear.Array2DRowRealMatrix;\nimport org.apache.commons.math3.linear.RealMatrix;\nimport org.apache.commons.math3.optim.OptimizationData;\nimport org.apache.commons.math3.optim.PointValuePair;\nimport org.apache.commons.math3.optim.nonlinear.scalar.GoalType;\nimport org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\nimport org.apache.commons.math3.optim.nonlinear.scalar.ObjectiveFunction;\nimport org.apache.commons.math3.optim.nonlinear.scalar.ObjectiveFunctionGradient;\nimport org.apache.commons.math3.optim.nonlinear.scalar.noderiv.AbstractSimplex;\nimport org.apache.commons.math3.optim.nonlinear.scalar.noderiv.AbstractSimplexOptimizer;\nimport org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizer;\nimport org.apache.commons.math3.optim.nonlinear.scalar.noderiv.NelderMeadSimplex;\nimport org.apache.commons.math3.util.FastMath;\n\nimport java.util.Comparator;\n\npublic class Minimizer extends AbstractSimplexOptimizer {\n\n    /**\n     * Default amount of allowed evaluations of the objective function.\n     */\n    public static final int DEFAULT_MAX_ITERATIONS = 20000;\n\n    private RealMatrix covarMatrix;\n\n    private RealMatrix jacobian;\n\n    private int nparams;\n\n    private int ndata;\n\n    protected double[] weights;\n\n    protected boolean[] valid;\n\n    protected LeastSquaresConverter converter;\n\n    public Minimizer() {\n        super(DEFAULT_MAX_ITERATIONS);\n    }\n\n    public void computeCovarMatrix(PointValuePair optimum) throws MathIllegalStateException {\n\n        final double EPS_TOL = 10E-14;\n\n        final int n = converter.getNumParams();\n        RealMatrix alpha = new Array2DRowRealMatrix(n, n);\n        double[] beta = new double[n];\n        double sumSquares = 0;\n\n        final double[] residuals = converter.getResiduals(optimum.getPoint().toArray());\n\n        for (int i = 0; i < ndata; ++i) {\n            final double[] point = converter.getJacobian(optimum.getPoint().toArray(), i);\n            final double weight_i = FastMath.sqrt(weights[i]);\n\n            final double tmp = weight_i * residuals[i];\n            for (int j = 0; j < n; ++j) {\n                beta[j] += tmp * point[j];\n            }\n\n            sumSquares += weight_i * weight_i * residuals[i] * residuals[i];\n\n            for (int k = 0; k < n; ++k) {\n\n                final double[] ak = converter.getJacobian(optimum.getPoint().toArray(), i);\n\n                for (int l = 0; l < n; ++l) {\n                    alpha.setEntry(k, l, alpha.getEntry(k, l) + ak[l] * ak[k] * weights[i]);\n                }\n            }\n\n        }\n\n        final double[][] alphaArray = alpha.getData();\n        final double[] bnew = new double[n];\n\n        for (int i = 0; i < n; ++i) {\n            for (int j = 0; j < n; ++j) {\n                bnew[i] += alphaArray[i][j] * optimum.getPoint().toArray()[j];\n            }\n            bnew[i] -= beta[i];\n        }\n\n        int[] indx = new int[n];\n        double d = ludcmp(alphaArray, indx);\n        if (d == 0) { // singular matrix. On this case, unset any previously set covariance and return\n            covarMatrix = null;\n            return;\n        }\n        //TODO magic number\n        if (d < EPS_TOL) { // small determinant, covariance matrix must be singular\n            System.out.println(\"WARNING: covariance matrix close to singular!\");\n        }\n\n        double[] x = new double[n];\n        for (int i = 0; i < n; ++i) {\n            x[i] = bnew[i];\n        }\n        lubksb(alphaArray, indx, x);\n\n        final double[][] covArray = new double[n][n];\n        for (int i = 0; i < n; ++i) {\n            for (int j = 0; j < n; ++j) {\n                covArray[i][j] = alphaArray[i][j] * 2 * sumSquares / (ndata - n) * ((i != j) ? 1.0 : 1.0 + EPS_TOL) + ((x[i] * x[j]) / (ndata - n));\n            }\n        }\n\n        //Calculate the chisq\n        double chisq = 0;\n        for (int i = 0; i < ndata; ++i) {\n\n            final double[] point = converter.getJacobian(optimum.getPoint().toArray(), i);\n            final double model_i = converter.getModelFunction(optimum.getPoint().toArray(), i);\n            final double weight_i = FastMath.sqrt(weights[i]);\n\n            double t = (converter.getY(i) - model_i) / (weight_i);\n            chisq += t * t;\n        }\n        chisq /= (ndata - n);\n\n        valid = findValidCovar(covArray);\n\n        // no valid covariance could be computed, revert to null\n        if (!valid[0]) {\n            covarMatrix = null;\n            return;\n        }\n\n        covarMatrix = new Array2DRowRealMatrix(covArray, false);\n    }\n\n    private boolean[] findValidCovar(double[][] covarArray) {\n\n        boolean[] valid = new boolean[]{true, true, true, true, true, true, true};\n        double[][] npArray = new double[7][7];\n        npArray[0] = new double[]{1, 0, 0, 0, 0, 0, 0};\n        npArray[1] = new double[]{1, 1, 0, 0, 0, 0, 0};\n        npArray[2] = new double[]{1, 1, 1, 0, 0, 0, 0};\n        npArray[3] = new double[]{0, 1, 1, 1, 0, 0, 0};\n        npArray[4] = new double[]{0, 0, 1, 1, 1, 0, 0};\n        npArray[5] = new double[]{0, 0, 0, 1, 1, 1, 0};\n        npArray[6] = new double[]{0, 0, 0, 0, 1, 1, 1};\n\n        RealMatrix np = new Array2DRowRealMatrix(npArray, false);\n\n        for (int i = 0; i < 7; i++) {\n            final RealMatrix subMatrix = new Array2DRowRealMatrix(subMatrix(covarArray, i), false);\n            final double d = new org.apache.commons.math3.linear.LUDecomposition(subMatrix).getDeterminant();\n            if (d <= 0.0) {\n                valid[i] = false;\n\n                if (i == 0) {\n                    // Entire covar is invalid.\n                    return new boolean[]{false, false, false, false, false, false, false};\n                }\n            }\n        }\n\n        return valid;\n    }\n\n    private double[][] subMatrix(final double[][] matrix, final int index) {\n\n        int rows = matrix.length - 1;\n        int cols = matrix[0].length - 1;\n\n        double[][] subArr = new double[rows][cols];\n\n        int row = -1;\n        for (int i = 1; i < matrix.length; i++) {\n            if (i == index + 1) {\n                continue;\n            }\n            row++;\n            int col = -1;\n            for (int j = 1; j < matrix[0].length; j++) {\n                if (j == index + 1) {\n                    continue;\n                }\n                subArr[row][++col] = matrix[i][j];\n            }\n        }\n\n        return subArr;\n    }\n\n    public RealMatrix computeJacobian(PointValuePair optimum) {\n        for (int i = 0; i < ndata; ++i) {\n            final double[] point = converter.getJacobian(optimum.getPoint().toArray(), i);\n            for (int j = 0; j < nparams; ++j) {\n                jacobian.setEntry(i, j, point[j]);\n            }\n        }\n        return jacobian;\n    }\n\n    @Override\n    protected PointValuePair doOptimize() throws TooManyEvaluationsException {\n\n        double[] guess = getStartPoint().toArray();\n        this.weights = converter.getWeights();\n\n        this.nparams = guess.length;\n        this.ndata   = converter.getN();\n\n        jacobian     = new Array2DRowRealMatrix(ndata, nparams);\n\n        final MultivariateOptimizer optimizer = getOptimizer();\n\n        // This is a hack to use simplex with gradient optimizer\n        if (optimizer instanceof SimplexOptimizer &&\n                optimizer instanceof AbstractSimplexOptimizer) {\n            final AbstractSimplex simplex = ((Simple",
    "patch_diff": "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex 50914932e..99413a81f 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -238,231 +238,224 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n     /** {@inheritDoc} */\n     @Override\n-    protected VectorialPointValuePair doOptimize()\n-        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n-\n-        // arrays shared with the other private methods\n-        solvedCols  = Math.min(rows, cols);\n-        diagR       = new double[cols];\n-        jacNorm     = new double[cols];\n-        beta        = new double[cols];\n-        permutation = new int[cols];\n-        lmDir       = new double[cols];\n-\n-        // local point\n-        double   delta   = 0;\n-        double   xNorm   = 0;\n-        double[] diag    = new double[cols];\n-        double[] oldX    = new double[cols];\n-        double[] oldRes  = new double[rows];\n-        double[] work1   = new double[cols];\n-        double[] work2   = new double[cols];\n-        double[] work3   = new double[cols];\n-\n-        // evaluate the function at the starting point and calculate its norm\n-        updateResidualsAndCost();\n-\n-        // outer loop\n-        lmPar = 0;\n-        boolean firstIteration = true;\n-        VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n-        while (true) {\n-            incrementIterationsCounter();\n-\n-            // compute the Q.R. decomposition of the jacobian matrix\n-            VectorialPointValuePair previous = current;\n-            updateJacobian();\n-            qrDecomposition();\n-\n-            // compute Qt.res\n-            qTy(residuals);\n-            // now we don't need Q anymore,\n-            // so let jacobian contain the R matrix with its diagonal elements\n-            for (int k = 0; k < solvedCols; ++k) {\n-                int pk = permutation[k];\n-                jacobian[k][pk] = diagR[pk];\n-            }\n+import org.apache.commons.math3.exception.MathIllegalStateException;\n+import org.apache.commons.math3.exception.TooManyEvaluationsException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+import org.apache.commons.math3.linear.Array2DRowRealMatrix;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.PointValuePair;\n+import org.apache.commons.math3.optim.nonlinear.scalar.GoalType;\n+import org.apache.commons.math3.optim.nonlinear.scalar.MultivariateOptimizer;\n+import org.apache.commons.math3.optim.nonlinear.scalar.ObjectiveFunction;\n+import org.apache.commons.math3.optim.nonlinear.scalar.ObjectiveFunctionGradient;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.AbstractSimplex;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.AbstractSimplexOptimizer;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.SimplexOptimizer;\n+import org.apache.commons.math3.optim.nonlinear.scalar.noderiv.NelderMeadSimplex;\n+import org.apache.commons.math3.util.FastMath;\n+\n+import java.util.Comparator;\n+\n+public class Minimizer extends AbstractSimplexOptimizer {\n \n-            if (firstIteration) {\n+    /**\n+     * Default amount of allowed evaluations of the objective function.\n+     */\n+    public static final int DEFAULT_MAX_ITERATIONS = 20000;\n \n-                // scale the point according to the norms of the columns\n-                // of the initial jacobian\n-                xNorm = 0;\n-                for (int k = 0; k < cols; ++k) {\n-                    double dk = jacNorm[k];\n-                    if (dk == 0) {\n-                        dk = 1.0;\n-                    }\n-                    double xk = dk * point[k];\n-                    xNorm  += xk * xk;\n-                    diag[k] = dk;\n-                }\n-                xNorm = Math.sqrt(xNorm);\n+    private RealMatrix covarMatrix;\n+\n+    private RealMatrix jacobian;\n+\n+    private int nparams;\n+\n+    private int ndata;\n+\n+    protected double[] weights;\n \n-                // initialize the step bound delta\n-                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n+    protected boolean[] valid;\n \n+    protected LeastSquaresConverter converter;\n+\n+    public Minimizer() {\n+        super(DEFAULT_MAX_ITERATIONS);\n+    }\n+\n+    public void computeCovarMatrix(PointValuePair optimum) throws MathIllegalStateException {\n+\n+        final double EPS_TOL = 10E-14;\n+\n+        final int n = converter.getNumParams();\n+        RealMatrix alpha = new Array2DRowRealMatrix(n, n);\n+        double[] beta = new double[n];\n+        double sumSquares = 0;\n+\n+        final double[] residuals = converter.getResiduals(optimum.getPoint().toArray());\n+\n+        for (int i = 0; i < ndata; ++i) {\n+            final double[] point = converter.getJacobian(optimum.getPoint().toArray(), i);\n+            final double weight_i = FastMath.sqrt(weights[i]);\n+\n+            final double tmp = weight_i * residuals[i];\n+            for (int j = 0; j < n; ++j) {\n+                beta[j] += tmp * point[j];\n             }\n \n-            // check orthogonality between function vector and jacobian columns\n-            double maxCosine = 0;\n-            if (cost != 0) {\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int    pj = permutation[j];\n-                    double s  = jacNorm[pj];\n-                    if (s != 0) {\n-                        double sum = 0;\n-                        for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * residuals[i];\n-                        }\n-                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n-                    }\n+            sumSquares += weight_i * weight_i * residuals[i] * residuals[i];\n+\n+            for (int k = 0; k < n; ++k) {\n+\n+                final double[] ak = converter.getJacobian(optimum.getPoint().toArray(), i);\n+\n+                for (int l = 0; l < n; ++l) {\n+                    alpha.setEntry(k, l, alpha.getEntry(k, l) + ak[l] * ak[k] * weights[i]);\n                 }\n             }\n-            if (maxCosine <= orthoTolerance) {\n-                // convergence has been reached\n-                return current;\n+\n+        }\n+\n+        final double[][] alphaArray = alpha.getData();\n+        final double[] bnew = new double[n];\n+\n+        for (int i = 0; i < n; ++i) {\n+            for (int j = 0; j < n; ++j) {\n+                bnew[i] += alphaArray[i][j] * optimum.getPoint().toArray()[j];\n             }\n+            bnew[i] -= beta[i];\n+        }\n+\n+        int[] indx = new int[n];\n+        double d = ludcmp(alphaArray, indx);\n+        if (d == 0) { // singular matrix. On this case, unset any previously set covariance and return\n+            covarMatrix = null;\n+            return;\n+        }\n+        //TODO magic number\n+        if (d < EPS_TOL) { // small determinant, covariance matrix must be singular\n+            System.out.println(\"WARNING: covariance matrix close to singular!\");\n+        }\n+\n+        double[] x = new double[n];\n+        for (int i = 0; i < n; ++i) {\n+            x[i] = bnew[i];\n+        }\n+        lubksb(alphaArray, indx, x);\n \n-            // rescale if necessary\n-            for (int j = 0; j < cols; ++j) {\n-                diag[j] = Math.max(diag[j], jacNorm[j]);\n+        final double[][] covArray = new double[n][n];\n+        for (int i = 0; i < n; ++i) {\n+            for (int j = 0; j < n; ++j) {\n+                covArray[i][j] = alphaArray[i][j] * 2 * sumSquares / (ndata - n) * ((i != j) ? 1.0 : 1.0 + EPS_TOL) + ((x[i] * x[j]) / (ndata - n));\n             }\n+        }\n \n-            // inner loop\n-            for (double ratio = 0; ratio < 1.0e-4;) {\n+        //Calculate the chisq\n+        double chisq = 0;\n+        for (int i = 0; i < ndata; ++i) {\n \n-                // save the state\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    oldX[pj] = point[pj];\n-                }\n-                double previousCost = cost;\n-                double[] tmpVec = residuals;\n-                residuals = oldRes;\n-                oldRes    = tmpVec;\n-\n-                // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n-\n-                // compute the new point and the norm of the evolution direction\n-                double lmNorm = 0;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    lmDir[pj] = -lmDir[pj];\n-                    point[pj] = oldX[pj] + lmDir[pj];\n-                    double s = diag[pj] * lmDir[pj];\n-                    lmNorm  += s * s;\n-                }\n-                lmNorm = Math.sqrt(lmNorm);\n-                // on the first iteration, adjust the initial step bound.\n-                if (firstIteration) {\n-                    delta = Math.min(delta, lmNorm);\n-                }\n+            final double[] point = converter.getJacobian(optimum.getPoint().toArray(), i);\n+            final double model_i = converter.getModelFunction(optimum.getPoint().toArray(), i);\n+            final double weight_i = FastMath.sqrt(weights[i]);\n \n-                // evaluate the function at x + p and calculate its norm\n-                updateResidualsAndCost();\n-                current = new VectorialPointValuePair(point, objective);\n+            double t = (converter.getY(i) - model_i) / (weight_i);\n+            chisq += t * t;\n+        }\n+        chisq /= (ndata - n);\n \n-                // compute the scaled actual reduction\n-                double actRed = -1.0;\n-                if (0.1 * cost < previousCost) {\n-                    double r = cost / previousCost;\n-                    actRed = 1.0 - r * r;\n-                }\n+        valid = findValidCovar(covArray);\n \n-                // compute the scaled predicted reduction\n-                // and the scaled directional derivative\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    double dirJ = lmDir[pj];\n-                    work1[j] = 0;\n-                    for (int i = 0; i <= j; ++i) {\n-                        work1[i] += jacobian[i][pj] * dirJ;\n-                    }\n-                }\n-                double coeff1 = 0;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    coeff1 += work1[j] * work1[j];\n-                }\n-                double pc2 = previousCost * previousCost;\n-                coeff1 = coeff1 / pc2;\n-                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n-                double preRed = coeff1 + 2 * coeff2;\n-                double dirDer = -(coeff1 + coeff2);\n-\n-                // ratio of the actual to the predicted reduction\n-                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n-\n-                // update the step bound\n-                if (ratio <= 0.25) {\n-                    double tmp =\n-                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n-                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n-                            tmp = 0.1;\n-                        }\n-                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n-                        lmPar /= tmp;\n-                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n-                    delta = 2 * lmNorm;\n-                    lmPar *= 0.5;\n-                }\n+        // no valid covariance could be computed, revert to null\n+        if (!valid[0]) {\n+            covarMatrix = null;\n+            return;\n+        }\n \n-                // test for successful iteration.\n-                if (ratio >= 1.0e-4) {\n-                    // successful iteration, update the norm\n-                    firstIteration = false;\n-                    xNorm = 0;\n-                    for (int k = 0; k < cols; ++k) {\n-                        double xK = diag[k] * point[k];\n-                        xNorm    += xK * xK;\n-                    }\n-                    xNorm = Math.sqrt(xNorm);\n-\n-                    // tests for convergence.\n-                    // we use the vectorial convergence checker\n-                } else {\n-                    // failed iteration, reset the previous values\n-                    cost = previousCost;\n-                    for (int j = 0; j < solvedCols; ++j) {\n-                        int pj = permutation[j];\n-                        point[pj] = oldX[pj];\n-                    }\n-                    tmpVec    = residuals;\n-                    residuals = oldRes;\n-                    oldRes    = tmpVec;\n-                }\n-                if (checker==null) {\n-                \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n-                        (preRed <= costRelativeTolerance) &&\n-                        (ratio <= 2.0)) ||\n-                       (delta <= parRelativeTolerance * xNorm)) {\n-                       return current;\n-                   }\n-                } else {\n-                    if (checker.converged(getIterations(), previous, current)) {\n-                        return current;\n-                    }\n-                }\n-                // tests for termination and stringent tolerances\n-                // (2.2204e-16 is the machine epsilon for IEEE754)\n-                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n-                            costRelativeTolerance);\n-                } else if (delta <= 2.2204e-16 * xNorm) {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n-                            parRelativeTolerance);\n-                } else if (maxCosine <= 2.2204e-16)  {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n-                            orthoTolerance);\n-                }\n+        covarMatrix = new Array2DRowRealMatrix(covArray, false);\n+    }\n \n+    private boolean[] findValidCovar(double[][] covarArray) {\n+\n+        boolean[] valid = new boolean[]{true, true, true, true, true, true, true};\n+        double[][] npArray = new double[7][7];\n+        npArray[0] = new double[]{1, 0, 0, 0, 0, 0, 0};\n+        npArray[1] = new double[]{1, 1, 0, 0, 0, 0, 0};\n+        npArray[2] = new double[]{1, 1, 1, 0, 0, 0, 0};\n+        npArray[3] = new double[]{0, 1, 1, 1, 0, 0, 0};\n+        npArray[4] = new double[]{0, 0, 1, 1, 1, 0, 0};\n+        npArray[5] = new double[]{0, 0, 0, 1, 1, 1, 0};\n+        npArray[6] = new double[]{0, 0, 0, 0, 1, 1, 1};\n+\n+        RealMatrix np = new Array2DRowRealMatrix(npArray, false);\n+\n+        for (int i = 0; i < 7; i++) {\n+            final RealMatrix subMatrix = new Array2DRowRealMatrix(subMatrix(covarArray, i), false);\n+            final double d = new org.apache.commons.math3.linear.LUDecomposition(subMatrix).getDeterminant();\n+            if (d <= 0.0) {\n+                valid[i] = false;\n+\n+                if (i == 0) {\n+                    // Entire covar is invalid.\n+                    return new boolean[]{false, false, false, false, false, false, false};\n+                }\n             }\n+        }\n+\n+        return valid;\n+    }\n+\n+    private double[][] subMatrix(final double[][] matrix, final int index) {\n+\n+        int rows = matrix.length - 1;\n+        int cols = matrix[0].length - 1;\n \n+        double[][] subArr = new double[rows][cols];\n+\n+        int row = -1;\n+        for (int i = 1; i < matrix.length; i++) {\n+            if (i == index + 1) {\n+                continue;\n+            }\n+            row++;\n+            int col = -1;\n+            for (int j = 1; j < matrix[0].length; j++) {\n+                if (j == index + 1) {\n+                    continue;\n+                }\n+                subArr[row][++col] = matrix[i][j];\n+            }\n         }\n \n+        return subArr;\n+    }\n+\n+    public RealMatrix computeJacobian(PointValuePair optimum) {\n+        for (int i = 0; i < ndata; ++i) {\n+            final double[] point = converter.getJacobian(optimum.getPoint().toArray(), i);\n+            for (int j = 0; j < nparams; ++j) {\n+                jacobian.setEntry(i, j, point[j]);\n+            }\n+        }\n+        return jacobian;\n     }\n \n+    @Override\n+    protected PointValuePair doOptimize() throws TooManyEvaluationsException {\n+\n+        double[] guess = getStartPoint().toArray();\n+        this.weights = converter.getWeights();\n+\n+        this.nparams = guess.length;\n+        this.ndata   = converter.getN();\n+\n+        jacobian     = new Array2DRowRealMatrix(ndata, nparams);\n+\n+        final MultivariateOptimizer optimizer = getOptimizer();\n+\n+        // This is a hack to use simplex with gradient optimizer\n+        if (optimizer instanceof SimplexOptimizer &&\n+                optimizer instanceof AbstractSimplexOptimizer) {\n+            final AbstractSimplex simplex = ((Simple\n+\n     /**\n      * Determine the Levenberg-Marquardt parameter.\n      * <p>This implementation is a translation in Java of the MINPACK",
    "result_reason": "error: illegal start of type",
    "test_result": "ERROR"
}