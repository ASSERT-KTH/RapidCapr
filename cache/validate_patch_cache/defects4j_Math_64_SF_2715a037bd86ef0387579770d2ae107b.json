{
    "patch": "import org.apache.commons.math3.exception.OptimizationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.linear.DecompositionSolver;\nimport org.apache.commons.math3.linear.LUDecomposition;\nimport org.apache.commons.math3.linear.RealMatrix;\nimport org.apache.commons.math3.optim.ConvergenceChecker;\nimport org.apache.commons.math3.util.FastMath;\n\nimport java.util.Arrays;\n\npublic class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n\n    /** Default maximal number of iterations allowed. */\n    public static final int DEFAULT_MAX_ITERATIONS = 1000;\n    /** Default Levenberg-Marquardt parameter. */\n    public static final double DEFAULT_LAMBDA = 1e-2;\n    /** Default stopping threshold for convergence. */\n    public static final double DEFAULT_CONVERGENCE = 1e-4;\n\n    /** Levenberg-Marquardt parameter. */\n    private double lambda;\n    /** Diagonal elements of the R matrix in the QR decomposition. */\n    private double[] diagR;\n    /** Cached decomposition algorithm. */\n    private DecompositionSolver cachedDecomposition;\n    /** Singularity threshold (should be related to machine epsilon). */\n    private final double singularityThreshold;\n    /** Update function. */\n    private final UpdateFunction update;\n    /** Convergence checker. */\n    private final ConvergenceChecker<PointVectorValuePair> checker;\n\n    /**\n     * Create an instance with default settings.\n     * The default settings are:\n     * <ul>\n     *  <li>{@link #DEFAULT_MAX_ITERATIONS maximal number of iterations} set to 1000</li>\n     *  <li>{@link #DEFAULT_LAMBDA Levenberg-Marquardt parameter} set to 0.01</li>\n     *  <li>stopping criterion set to {@link #DEFAULT_CONVERGENCE}</li>\n     *  <li>{@link UpdateFunction#DEFAULT} update function}</li>\n     * </ul>\n     *\n     * @see #DEFAULT_MAX_ITERATIONS\n     * @see #DEFAULT_LAMBDA\n     * @see #DEFAULT_CONVERGENCE\n     */\n    public LevenbergMarquardtOptimizer() {\n        this(DEFAULT_MAX_ITERATIONS, DEFAULT_LAMBDA, DEFAULT_CONVERGENCE,\n             UpdateFunction.DEFAULT, new SimpleVectorValueChecker());\n    }\n\n    /**\n     * Create an instance with specified convergence checker.\n     * The other parameters of the algorithm will be set to default values.\n     *\n     * @param checker Convergence checker.\n     */\n    public LevenbergMarquardtOptimizer(final ConvergenceChecker<PointVectorValuePair> checker) {\n        this(DEFAULT_MAX_ITERATIONS, DEFAULT_LAMBDA, DEFAULT_CONVERGENCE,\n             UpdateFunction.DEFAULT, checker);\n    }\n\n    /**\n     * Create an instance with specified algorithm settings.\n     *\n     * @param maxIterations Maximal number of iterations allowed.\n     * @param lambda Levenberg-Marquardt parameter.\n     * @param convergenceThreshold Threshold for stopping iterations.\n     */\n    public LevenbergMarquardtOptimizer(final int maxIterations, final double lambda,\n                                       final double convergenceThreshold) {\n        this(maxIterations, lambda, convergenceThreshold, UpdateFunction.DEFAULT,\n             new SimpleVectorValueChecker());\n    }\n\n    /**\n     * Create an instance with specified algorithm settings.\n     *\n     * @param maxIterations Maximal number of iterations allowed.\n     * @param lambda Levenberg-Marquardt parameter.\n     * @param convergenceThreshold Threshold for stopping iterations.\n     * @param update Updater to use for QR decomposition.\n     * @param checker Convergence checker.\n     */\n    public LevenbergMarquardtOptimizer(final int maxIterations, final double lambda,\n                                       final double convergenceThreshold,\n                                       final UpdateFunction update,\n                                       final ConvergenceChecker<PointVectorValuePair> checker) {\n        super(checker);\n        this.lambda     = lambda;\n        setMaxIterations(maxIterations);\n        setConvergenceChecker(checker);\n        this.update     = update;\n        this.checker    = checker;\n        singularityThreshold = FastMath.sqrt(Formula.EPSILON);\n    }\n\n    /**\n     * Performs the optimization.\n     *\n     * @return the point/value pair giving the optimal value of the objective\n     * function.\n     * @throws OptimizationException if the algorithm failed to converge.\n     */\n    @Override\n    protected PointVectorValuePair doOptimize() throws FunctionEvaluationException {\n        final double[] targetValues = getTarget();\n        final double[] weights      = getWeight();\n        final double[] startPoint  = getStartPoint();\n\n        final int nC = startPoint.length;\n        final int nR = targetValues.length;\n\n        final ModelFunction model = getModelFunction();\n        final GradientFunction gradient = getGradientFunction();\n        final ValueAndJacobianFunction valueAndJacobianFunction =\n                new ValueAndJacobianFunction(model, gradient);\n\n        final double[] currentPoint = Arrays.copyOf(startPoint, nC);\n\n        double[] residuals               = new double[nR];\n        double[][] weightedJacobian      = new double[nR][nC];\n        double[][] lhs                   = new double[nC][nC];\n        double[] diag = new double[nC];\n        double[] beta = new double[nC];\n        double[] solved = new double[nC];\n\n        final double initialCost = computeCost(valueAndJacobianFunction, currentPoint, residuals,\n                                                weightedJacobian, targetValues, weights);\n        final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n        PointVectorValuePair current = new PointVectorValuePair(currentPoint, residuals);\n        if (checker != null && checker.converged(getIterations(), current, null)) {\n            return current;\n        }\n\n        double cost = initialCost;\n        for (int iter = 0; iter < getMaxIterations(); ++iter) {\n\n            // Compute Jacobian and residuals.\n            computeWeightedJacobian(weightedJacobian, model, currentPoint, targetValues, weights);\n            computeResiduals(residuals, currentPoint, targetValues, weights, model);\n\n            // Build linear system.\n            for (int i = 0; i < nR; ++i) {\n                final double[] rowJ = weightedJacobian[i];\n                for (int j = 0; j <= i; ++j) {\n                    double sum = 0;\n                    for (int k = 0; k < nC; ++k) {\n                        sum += rowJ[k] * weightedJacobian[j][k];\n                    }\n                    lhs[i][j] = sum;\n                    lhs[j][i] = sum;\n                }\n            }\n\n            // Build the jacobian matrix and the residuals vector from weighted.\n            for (int i = 0; i < nC; ++i) {\n                diag[i] = lhs[i][i];\n                beta[i] = residuals[i];\n            }\n\n            // Solve the linear equation.\n            if (iter == 0) {\n                double initialNorm = 0;\n                for (int i = 0; i < nR; ++i) {\n                    initialNorm += residuals[i] * residuals[i];\n                }\n                initialNorm = FastMath.sqrt(initialNorm);\n                double threshold =\n                        FastMath.max(singularityThreshold,\n                                     getRelativeThreshold().multiply(initialNorm).doubleValue());\n                cachedDecomposition = new LUDecomposition(new Array2DRowRealMatrix(lhs), threshold);\n            }\n            RealMatrixUtils.solveUpperTriangular(cachedDecomposition.getU(), beta);\n            cachedDecomposition.getSolver().solve(beta, solved);\n\n            // Update the estimated values.\n            update.update(currentPoint, solved, diag, lhs, valueAndJacobianFunction,\n                           targetValues, weights);\n\n            final double[] newResiduals = new double[nR];\n            final double newCost = computeCost(valueAndJacobianFunction, currentPoint, newResiduals,\n                                                  weightedJacobian, targetValues, weights);\n\n            // Check convergence.\n            final PointVectorValuePair previous = current;\n            current = new PointVectorValuePair(currentPoint, newResiduals);\n            if (checker != null && checker.converged(getIterations(), previous, current)) {\n                return current;\n            }\n\n            // Prepare next iteration.\n            if (newCost < cost) {\n                lambda *= 0.1;\n                cost = newCost;\n            } else {\n                lambda *= 10;\n            }\n\n            if (cost <= getChiSquare()) {",
    "patch_diff": "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex 50914932e..a14c5b7b8 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -238,230 +238,206 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n     /** {@inheritDoc} */\n     @Override\n-    protected VectorialPointValuePair doOptimize()\n-        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n-\n-        // arrays shared with the other private methods\n-        solvedCols  = Math.min(rows, cols);\n-        diagR       = new double[cols];\n-        jacNorm     = new double[cols];\n-        beta        = new double[cols];\n-        permutation = new int[cols];\n-        lmDir       = new double[cols];\n-\n-        // local point\n-        double   delta   = 0;\n-        double   xNorm   = 0;\n-        double[] diag    = new double[cols];\n-        double[] oldX    = new double[cols];\n-        double[] oldRes  = new double[rows];\n-        double[] work1   = new double[cols];\n-        double[] work2   = new double[cols];\n-        double[] work3   = new double[cols];\n-\n-        // evaluate the function at the starting point and calculate its norm\n-        updateResidualsAndCost();\n-\n-        // outer loop\n-        lmPar = 0;\n-        boolean firstIteration = true;\n-        VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n-        while (true) {\n-            incrementIterationsCounter();\n-\n-            // compute the Q.R. decomposition of the jacobian matrix\n-            VectorialPointValuePair previous = current;\n-            updateJacobian();\n-            qrDecomposition();\n-\n-            // compute Qt.res\n-            qTy(residuals);\n-            // now we don't need Q anymore,\n-            // so let jacobian contain the R matrix with its diagonal elements\n-            for (int k = 0; k < solvedCols; ++k) {\n-                int pk = permutation[k];\n-                jacobian[k][pk] = diagR[pk];\n-            }\n+import org.apache.commons.math3.exception.OptimizationException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+import org.apache.commons.math3.linear.DecompositionSolver;\n+import org.apache.commons.math3.linear.LUDecomposition;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.optim.ConvergenceChecker;\n+import org.apache.commons.math3.util.FastMath;\n \n-            if (firstIteration) {\n+import java.util.Arrays;\n \n-                // scale the point according to the norms of the columns\n-                // of the initial jacobian\n-                xNorm = 0;\n-                for (int k = 0; k < cols; ++k) {\n-                    double dk = jacNorm[k];\n-                    if (dk == 0) {\n-                        dk = 1.0;\n-                    }\n-                    double xk = dk * point[k];\n-                    xNorm  += xk * xk;\n-                    diag[k] = dk;\n-                }\n-                xNorm = Math.sqrt(xNorm);\n+public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n-                // initialize the step bound delta\n-                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n+    /** Default maximal number of iterations allowed. */\n+    public static final int DEFAULT_MAX_ITERATIONS = 1000;\n+    /** Default Levenberg-Marquardt parameter. */\n+    public static final double DEFAULT_LAMBDA = 1e-2;\n+    /** Default stopping threshold for convergence. */\n+    public static final double DEFAULT_CONVERGENCE = 1e-4;\n \n-            }\n+    /** Levenberg-Marquardt parameter. */\n+    private double lambda;\n+    /** Diagonal elements of the R matrix in the QR decomposition. */\n+    private double[] diagR;\n+    /** Cached decomposition algorithm. */\n+    private DecompositionSolver cachedDecomposition;\n+    /** Singularity threshold (should be related to machine epsilon). */\n+    private final double singularityThreshold;\n+    /** Update function. */\n+    private final UpdateFunction update;\n+    /** Convergence checker. */\n+    private final ConvergenceChecker<PointVectorValuePair> checker;\n \n-            // check orthogonality between function vector and jacobian columns\n-            double maxCosine = 0;\n-            if (cost != 0) {\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int    pj = permutation[j];\n-                    double s  = jacNorm[pj];\n-                    if (s != 0) {\n-                        double sum = 0;\n-                        for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * residuals[i];\n-                        }\n-                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n-                    }\n-                }\n-            }\n-            if (maxCosine <= orthoTolerance) {\n-                // convergence has been reached\n-                return current;\n-            }\n+    /**\n+     * Create an instance with default settings.\n+     * The default settings are:\n+     * <ul>\n+     *  <li>{@link #DEFAULT_MAX_ITERATIONS maximal number of iterations} set to 1000</li>\n+     *  <li>{@link #DEFAULT_LAMBDA Levenberg-Marquardt parameter} set to 0.01</li>\n+     *  <li>stopping criterion set to {@link #DEFAULT_CONVERGENCE}</li>\n+     *  <li>{@link UpdateFunction#DEFAULT} update function}</li>\n+     * </ul>\n+     *\n+     * @see #DEFAULT_MAX_ITERATIONS\n+     * @see #DEFAULT_LAMBDA\n+     * @see #DEFAULT_CONVERGENCE\n+     */\n+    public LevenbergMarquardtOptimizer() {\n+        this(DEFAULT_MAX_ITERATIONS, DEFAULT_LAMBDA, DEFAULT_CONVERGENCE,\n+             UpdateFunction.DEFAULT, new SimpleVectorValueChecker());\n+    }\n \n-            // rescale if necessary\n-            for (int j = 0; j < cols; ++j) {\n-                diag[j] = Math.max(diag[j], jacNorm[j]);\n-            }\n+    /**\n+     * Create an instance with specified convergence checker.\n+     * The other parameters of the algorithm will be set to default values.\n+     *\n+     * @param checker Convergence checker.\n+     */\n+    public LevenbergMarquardtOptimizer(final ConvergenceChecker<PointVectorValuePair> checker) {\n+        this(DEFAULT_MAX_ITERATIONS, DEFAULT_LAMBDA, DEFAULT_CONVERGENCE,\n+             UpdateFunction.DEFAULT, checker);\n+    }\n \n-            // inner loop\n-            for (double ratio = 0; ratio < 1.0e-4;) {\n+    /**\n+     * Create an instance with specified algorithm settings.\n+     *\n+     * @param maxIterations Maximal number of iterations allowed.\n+     * @param lambda Levenberg-Marquardt parameter.\n+     * @param convergenceThreshold Threshold for stopping iterations.\n+     */\n+    public LevenbergMarquardtOptimizer(final int maxIterations, final double lambda,\n+                                       final double convergenceThreshold) {\n+        this(maxIterations, lambda, convergenceThreshold, UpdateFunction.DEFAULT,\n+             new SimpleVectorValueChecker());\n+    }\n \n-                // save the state\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    oldX[pj] = point[pj];\n-                }\n-                double previousCost = cost;\n-                double[] tmpVec = residuals;\n-                residuals = oldRes;\n-                oldRes    = tmpVec;\n-\n-                // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n-\n-                // compute the new point and the norm of the evolution direction\n-                double lmNorm = 0;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    lmDir[pj] = -lmDir[pj];\n-                    point[pj] = oldX[pj] + lmDir[pj];\n-                    double s = diag[pj] * lmDir[pj];\n-                    lmNorm  += s * s;\n-                }\n-                lmNorm = Math.sqrt(lmNorm);\n-                // on the first iteration, adjust the initial step bound.\n-                if (firstIteration) {\n-                    delta = Math.min(delta, lmNorm);\n-                }\n+    /**\n+     * Create an instance with specified algorithm settings.\n+     *\n+     * @param maxIterations Maximal number of iterations allowed.\n+     * @param lambda Levenberg-Marquardt parameter.\n+     * @param convergenceThreshold Threshold for stopping iterations.\n+     * @param update Updater to use for QR decomposition.\n+     * @param checker Convergence checker.\n+     */\n+    public LevenbergMarquardtOptimizer(final int maxIterations, final double lambda,\n+                                       final double convergenceThreshold,\n+                                       final UpdateFunction update,\n+                                       final ConvergenceChecker<PointVectorValuePair> checker) {\n+        super(checker);\n+        this.lambda     = lambda;\n+        setMaxIterations(maxIterations);\n+        setConvergenceChecker(checker);\n+        this.update     = update;\n+        this.checker    = checker;\n+        singularityThreshold = FastMath.sqrt(Formula.EPSILON);\n+    }\n \n-                // evaluate the function at x + p and calculate its norm\n-                updateResidualsAndCost();\n-                current = new VectorialPointValuePair(point, objective);\n+    /**\n+     * Performs the optimization.\n+     *\n+     * @return the point/value pair giving the optimal value of the objective\n+     * function.\n+     * @throws OptimizationException if the algorithm failed to converge.\n+     */\n+    @Override\n+    protected PointVectorValuePair doOptimize() throws FunctionEvaluationException {\n+        final double[] targetValues = getTarget();\n+        final double[] weights      = getWeight();\n+        final double[] startPoint  = getStartPoint();\n+\n+        final int nC = startPoint.length;\n+        final int nR = targetValues.length;\n+\n+        final ModelFunction model = getModelFunction();\n+        final GradientFunction gradient = getGradientFunction();\n+        final ValueAndJacobianFunction valueAndJacobianFunction =\n+                new ValueAndJacobianFunction(model, gradient);\n+\n+        final double[] currentPoint = Arrays.copyOf(startPoint, nC);\n+\n+        double[] residuals               = new double[nR];\n+        double[][] weightedJacobian      = new double[nR][nC];\n+        double[][] lhs                   = new double[nC][nC];\n+        double[] diag = new double[nC];\n+        double[] beta = new double[nC];\n+        double[] solved = new double[nC];\n+\n+        final double initialCost = computeCost(valueAndJacobianFunction, currentPoint, residuals,\n+                                                weightedJacobian, targetValues, weights);\n+        final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n+        PointVectorValuePair current = new PointVectorValuePair(currentPoint, residuals);\n+        if (checker != null && checker.converged(getIterations(), current, null)) {\n+            return current;\n+        }\n \n-                // compute the scaled actual reduction\n-                double actRed = -1.0;\n-                if (0.1 * cost < previousCost) {\n-                    double r = cost / previousCost;\n-                    actRed = 1.0 - r * r;\n-                }\n+        double cost = initialCost;\n+        for (int iter = 0; iter < getMaxIterations(); ++iter) {\n \n-                // compute the scaled predicted reduction\n-                // and the scaled directional derivative\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    double dirJ = lmDir[pj];\n-                    work1[j] = 0;\n-                    for (int i = 0; i <= j; ++i) {\n-                        work1[i] += jacobian[i][pj] * dirJ;\n-                    }\n-                }\n-                double coeff1 = 0;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    coeff1 += work1[j] * work1[j];\n-                }\n-                double pc2 = previousCost * previousCost;\n-                coeff1 = coeff1 / pc2;\n-                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n-                double preRed = coeff1 + 2 * coeff2;\n-                double dirDer = -(coeff1 + coeff2);\n-\n-                // ratio of the actual to the predicted reduction\n-                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n-\n-                // update the step bound\n-                if (ratio <= 0.25) {\n-                    double tmp =\n-                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n-                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n-                            tmp = 0.1;\n-                        }\n-                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n-                        lmPar /= tmp;\n-                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n-                    delta = 2 * lmNorm;\n-                    lmPar *= 0.5;\n-                }\n+            // Compute Jacobian and residuals.\n+            computeWeightedJacobian(weightedJacobian, model, currentPoint, targetValues, weights);\n+            computeResiduals(residuals, currentPoint, targetValues, weights, model);\n \n-                // test for successful iteration.\n-                if (ratio >= 1.0e-4) {\n-                    // successful iteration, update the norm\n-                    firstIteration = false;\n-                    xNorm = 0;\n-                    for (int k = 0; k < cols; ++k) {\n-                        double xK = diag[k] * point[k];\n-                        xNorm    += xK * xK;\n-                    }\n-                    xNorm = Math.sqrt(xNorm);\n-\n-                    // tests for convergence.\n-                    // we use the vectorial convergence checker\n-                } else {\n-                    // failed iteration, reset the previous values\n-                    cost = previousCost;\n-                    for (int j = 0; j < solvedCols; ++j) {\n-                        int pj = permutation[j];\n-                        point[pj] = oldX[pj];\n-                    }\n-                    tmpVec    = residuals;\n-                    residuals = oldRes;\n-                    oldRes    = tmpVec;\n-                }\n-                if (checker==null) {\n-                \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n-                        (preRed <= costRelativeTolerance) &&\n-                        (ratio <= 2.0)) ||\n-                       (delta <= parRelativeTolerance * xNorm)) {\n-                       return current;\n-                   }\n-                } else {\n-                    if (checker.converged(getIterations(), previous, current)) {\n-                        return current;\n+            // Build linear system.\n+            for (int i = 0; i < nR; ++i) {\n+                final double[] rowJ = weightedJacobian[i];\n+                for (int j = 0; j <= i; ++j) {\n+                    double sum = 0;\n+                    for (int k = 0; k < nC; ++k) {\n+                        sum += rowJ[k] * weightedJacobian[j][k];\n                     }\n+                    lhs[i][j] = sum;\n+                    lhs[j][i] = sum;\n                 }\n-                // tests for termination and stringent tolerances\n-                // (2.2204e-16 is the machine epsilon for IEEE754)\n-                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n-                            costRelativeTolerance);\n-                } else if (delta <= 2.2204e-16 * xNorm) {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n-                            parRelativeTolerance);\n-                } else if (maxCosine <= 2.2204e-16)  {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n-                            orthoTolerance);\n+            }\n+\n+            // Build the jacobian matrix and the residuals vector from weighted.\n+            for (int i = 0; i < nC; ++i) {\n+                diag[i] = lhs[i][i];\n+                beta[i] = residuals[i];\n+            }\n+\n+            // Solve the linear equation.\n+            if (iter == 0) {\n+                double initialNorm = 0;\n+                for (int i = 0; i < nR; ++i) {\n+                    initialNorm += residuals[i] * residuals[i];\n                 }\n+                initialNorm = FastMath.sqrt(initialNorm);\n+                double threshold =\n+                        FastMath.max(singularityThreshold,\n+                                     getRelativeThreshold().multiply(initialNorm).doubleValue());\n+                cachedDecomposition = new LUDecomposition(new Array2DRowRealMatrix(lhs), threshold);\n+            }\n+            RealMatrixUtils.solveUpperTriangular(cachedDecomposition.getU(), beta);\n+            cachedDecomposition.getSolver().solve(beta, solved);\n+\n+            // Update the estimated values.\n+            update.update(currentPoint, solved, diag, lhs, valueAndJacobianFunction,\n+                           targetValues, weights);\n \n+            final double[] newResiduals = new double[nR];\n+            final double newCost = computeCost(valueAndJacobianFunction, currentPoint, newResiduals,\n+                                                  weightedJacobian, targetValues, weights);\n+\n+            // Check convergence.\n+            final PointVectorValuePair previous = current;\n+            current = new PointVectorValuePair(currentPoint, newResiduals);\n+            if (checker != null && checker.converged(getIterations(), previous, current)) {\n+                return current;\n             }\n \n-        }\n+            // Prepare next iteration.\n+            if (newCost < cost) {\n+                lambda *= 0.1;\n+                cost = newCost;\n+            } else {\n+                lambda *= 10;\n+            }\n \n-    }\n+            if (cost <= getChiSquare()) {\n \n     /**\n      * Determine the Levenberg-Marquardt parameter.",
    "result_reason": "error: illegal start of type",
    "test_result": "ERROR"
}