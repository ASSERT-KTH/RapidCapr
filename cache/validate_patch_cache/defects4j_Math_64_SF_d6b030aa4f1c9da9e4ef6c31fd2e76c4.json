{
    "patch": "import org.apache.commons.math3.exception.OptimizationException;\nimport org.apache.commons.math3.exception.util.LocalizedFormats;\nimport org.apache.commons.math3.linear.ArrayRealVector;\nimport org.apache.commons.math3.linear.DecompositionSolver;\nimport org.apache.commons.math3.linear.QRDecomposition;\nimport org.apache.commons.math3.linear.RealMatrix;\nimport org.apache.commons.math3.linear.RealVector;\nimport org.apache.commons.math3.optim.OptimizationData;\nimport org.apache.commons.math3.optim.PointVectorValuePair;\nimport org.apache.commons.math3.optim.nonlinear.vector.JacobianMultivariateVectorOptimizer;\nimport org.apache.commons.math3.optim.nonlinear.vector.MultivariateVectorFunction;\nimport org.apache.commons.math3.optim.nonlinear.vector.Weight;\nimport org.apache.commons.math3.util.FastMath;\n\npublic class LevenbergMarquardtOptimizer extends JacobianMultivariateVectorOptimizer {\n    /** Small number. */\n    private static final double EPSILON = 1.0e-10;\n    /** Initial step bound factor. */\n    private final double initialStepBoundFactor;\n    /** Cost relative tolerance. */\n    private final double costRelativeTolerance;\n    /** Parameters relative tolerance. */\n    private final double parRelativeTolerance;\n    /** Orthogonality tolerance. */\n    private final double orthoTolerance;\n    /** Levenberg-Marquardt parameter. */\n    private double lmPar;\n    /** Diagonal of the jacobian matrix. */\n    private double[] diag;\n    /** Cached QR decomposition of the jacobian matrix. */\n    private QRDecomposition cachedJacobian;\n    /** Cached weighted jacobian matrix. */\n    private RealMatrix weightedJacobian;\n    /** (J^T)J in the Levenberg-Marquardt algorithm. */\n    private RealMatrix jTj;\n    /** Values of the objective function. */\n    private double[] residuals;\n    /**\n     * Indicates whether the Jacobian matrix should be recalculated or\n     * not at the next iteration.\n     */\n    private boolean isJacobianUpdateRequired;\n    /** Diagonal matrix whose diagonal elements are the squares of the */\n    /** singular values of {@link #weightedJacobian}. */\n    private double[] diagR;\n    /** Norm of the residuals. */\n    private double cost;\n    /**\n     * Creates a new instance of this class, with default values for all\n     * algorithmic parameters.\n     */\n    public LevenbergMarquardtOptimizer() {\n        this(100, 1.0e-10, 1.0e-10, 1.0e-10);\n    }\n    /**\n     * Creates a new instance of this class with the specified values for\n     * the algorithmic parameters.\n     *\n     * @param initialStepBoundFactor Initial step bound factor.\n     * @param costRelativeTolerance Cost relative tolerance.\n     * @param parRelativeTolerance Parameters relative tolerance.\n     * @param orthoTolerance Orthogonality tolerance.\n     */\n    public LevenbergMarquardtOptimizer(double initialStepBoundFactor,\n                                       double costRelativeTolerance,\n                                       double parRelativeTolerance,\n                                       double orthoTolerance) {\n        this.initialStepBoundFactor = initialStepBoundFactor;\n        this.costRelativeTolerance = costRelativeTolerance;\n        this.parRelativeTolerance = parRelativeTolerance;\n        this.orthoTolerance = orthoTolerance;\n    }\n    /** {@inheritDoc} */\n    @Override\n    public PointVectorValuePair doOptimize() throws OptimizationException {\n        // Reset counters for iteration and evaluation and set\n        // flag to notify potential listeners that the algorithm has\n        // started.\n        iterations.incrementCount();\n        // Obtain the cost function.\n        final MultivariateVectorFunction objective = getObjectiveFunction();\n        // Retrieve weight matrix (null means equal weights).\n        final double[] targetValues = getTarget();\n        final Weight weightMatrix = getWeight();\n        // Get the initial guess as an ArrayRealVector.\n        RealVector currentPoint = new ArrayRealVector(getStartPoint());\n        // Determine the number of parameters.\n        final int n = currentPoint.getDimension();\n        // Compute the number of observations.\n        final int m = targetValues.length;\n        // Evaluate the model function and calculate the norm of the residuals.\n        RealVector currentObjective = new ArrayRealVector(m);\n        MatrixJacobian jacobian = new MatrixJacobian(m, n);\n        updateResidualsAndCost(objective, currentPoint, currentObjective, jacobian, weightMatrix, targetValues);\n        double currentCost = FastMath.sqrt(cost);\n        // Create a point-value pair for the current iteration.\n        PointVectorValuePair current = new PointVectorValuePair(currentPoint.toArray(), currentObjective.toArray());\n        // Set up iteration counter and flag.\n        int k = 0;\n        boolean converged = false;\n        // Outer loop.\n        lmPar = 0;\n        while (!converged) {\n            incrementIterationsCounter();\n            // Build the jacobian matrix.\n            updateJacobian(objective, currentPoint, jacobian);\n            // Build the weighted jacobian.\n            weightedJacobian = WeightedJacobian.compute(jacobian.getJacobianMatrix(), weightMatrix);\n            // Wrap the weighted jacobian in a matrix wrapper.\n            RealMatrix jT = weightedJacobian.transpose();\n            // Calculate JT * J.\n            jTj = jT.multiply(weightedJacobian);\n            // Now, add lambda to the diagonal elements of JTJ.\n            // Recall that lambda is related to the damping factor via:\n            // lambda = damping^2 * max(diagonal elements of JTJ).\n            lmPar = getDampingFactor(lmPar, jTj);\n            // Create a diagonal matrix from the diagonal elements of JTJ.\n            diagR = new double[n];\n            for (int i = 0; i < n; ++i) {\n                diagR[i] = jTj.getEntry(i, i);\n            }\n            // Compute the Q.R. decomposition of the jacobian matrix.\n            cachedJacobian = new QRDecomposition(weightedJacobian);\n            final double[][] qrt = cachedJacobian.getR().getData();\n            // Update the residuals.\n            isJacobianUpdateRequired = true;\n            if (k == 0) {\n                // Scale the point according to the norms of the columns\n                // of the initial jacobian.\n                diag = new double[n];\n                for (int j = 0; j < n; ++j) {\n                    diag[j] = qrt[j][j];\n                }\n                // Compute the norm of the scaled point.\n                double xNorm = currentPoint.getNorm();\n                double sgn = (currentPoint.dotProduct(currentObjective) >= 0) ? 1 : -1;\n                double initialStepBound = FastMath.min(initialStepBoundFactor * xNorm, 1.0e-3);\n                lmPar = 0;\n                // The outer loop continues only if the relative reduction\n                // in the objective function is not less than 0.1 percent.\n                if ((FastMath.sqrt(sumSquares(currentObjective)) / targetValues.length) < 0.1 * currentCost) {\n                    converged = true;\n                }\n            } else {\n                // Diagonal elements of the residual covariance matrix\n                // provide a measure of the scale of the uncertainties in\n                // the parameter estimates. We'll use scaled variables\n                // to better track such uncertainties.\n                for (int j = 0; j < n; ++j) {\n                    diag[j] = FastMath.sqrt(qrt[j][j]);\n                }\n                // Compute the norm of the current step.\n                double xNorm = currentPoint.getNorm();\n                double sgn = (currentPoint.dotProduct(currentObjective) >= 0) ? 1 : -1;\n                double initialStepBound = FastMath.min(initialStepBoundFactor * xNorm, 1.0e-3);\n                // The outer loop continues if the relative reduction in\n                // the objective function is greater than the threshold tol.\n                // Furthermore, if the step is small, convergence is determined.\n                if ((FastMath.abs(sumSquares(currentObjective) - currentCost)) / currentCost < costRelativeTolerance) {\n                    converged = true;\n                } else if (parRelativeTolerance*sumSquares(currentPoint) < initialStepBound*EPSILON) {\n                    converge",
    "patch_diff": "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex 50914932e..54869bca3 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -238,230 +238,168 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n     /** {@inheritDoc} */\n     @Override\n-    protected VectorialPointValuePair doOptimize()\n-        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n-\n-        // arrays shared with the other private methods\n-        solvedCols  = Math.min(rows, cols);\n-        diagR       = new double[cols];\n-        jacNorm     = new double[cols];\n-        beta        = new double[cols];\n-        permutation = new int[cols];\n-        lmDir       = new double[cols];\n-\n-        // local point\n-        double   delta   = 0;\n-        double   xNorm   = 0;\n-        double[] diag    = new double[cols];\n-        double[] oldX    = new double[cols];\n-        double[] oldRes  = new double[rows];\n-        double[] work1   = new double[cols];\n-        double[] work2   = new double[cols];\n-        double[] work3   = new double[cols];\n-\n-        // evaluate the function at the starting point and calculate its norm\n-        updateResidualsAndCost();\n-\n-        // outer loop\n+import org.apache.commons.math3.exception.OptimizationException;\n+import org.apache.commons.math3.exception.util.LocalizedFormats;\n+import org.apache.commons.math3.linear.ArrayRealVector;\n+import org.apache.commons.math3.linear.DecompositionSolver;\n+import org.apache.commons.math3.linear.QRDecomposition;\n+import org.apache.commons.math3.linear.RealMatrix;\n+import org.apache.commons.math3.linear.RealVector;\n+import org.apache.commons.math3.optim.OptimizationData;\n+import org.apache.commons.math3.optim.PointVectorValuePair;\n+import org.apache.commons.math3.optim.nonlinear.vector.JacobianMultivariateVectorOptimizer;\n+import org.apache.commons.math3.optim.nonlinear.vector.MultivariateVectorFunction;\n+import org.apache.commons.math3.optim.nonlinear.vector.Weight;\n+import org.apache.commons.math3.util.FastMath;\n+\n+public class LevenbergMarquardtOptimizer extends JacobianMultivariateVectorOptimizer {\n+    /** Small number. */\n+    private static final double EPSILON = 1.0e-10;\n+    /** Initial step bound factor. */\n+    private final double initialStepBoundFactor;\n+    /** Cost relative tolerance. */\n+    private final double costRelativeTolerance;\n+    /** Parameters relative tolerance. */\n+    private final double parRelativeTolerance;\n+    /** Orthogonality tolerance. */\n+    private final double orthoTolerance;\n+    /** Levenberg-Marquardt parameter. */\n+    private double lmPar;\n+    /** Diagonal of the jacobian matrix. */\n+    private double[] diag;\n+    /** Cached QR decomposition of the jacobian matrix. */\n+    private QRDecomposition cachedJacobian;\n+    /** Cached weighted jacobian matrix. */\n+    private RealMatrix weightedJacobian;\n+    /** (J^T)J in the Levenberg-Marquardt algorithm. */\n+    private RealMatrix jTj;\n+    /** Values of the objective function. */\n+    private double[] residuals;\n+    /**\n+     * Indicates whether the Jacobian matrix should be recalculated or\n+     * not at the next iteration.\n+     */\n+    private boolean isJacobianUpdateRequired;\n+    /** Diagonal matrix whose diagonal elements are the squares of the */\n+    /** singular values of {@link #weightedJacobian}. */\n+    private double[] diagR;\n+    /** Norm of the residuals. */\n+    private double cost;\n+    /**\n+     * Creates a new instance of this class, with default values for all\n+     * algorithmic parameters.\n+     */\n+    public LevenbergMarquardtOptimizer() {\n+        this(100, 1.0e-10, 1.0e-10, 1.0e-10);\n+    }\n+    /**\n+     * Creates a new instance of this class with the specified values for\n+     * the algorithmic parameters.\n+     *\n+     * @param initialStepBoundFactor Initial step bound factor.\n+     * @param costRelativeTolerance Cost relative tolerance.\n+     * @param parRelativeTolerance Parameters relative tolerance.\n+     * @param orthoTolerance Orthogonality tolerance.\n+     */\n+    public LevenbergMarquardtOptimizer(double initialStepBoundFactor,\n+                                       double costRelativeTolerance,\n+                                       double parRelativeTolerance,\n+                                       double orthoTolerance) {\n+        this.initialStepBoundFactor = initialStepBoundFactor;\n+        this.costRelativeTolerance = costRelativeTolerance;\n+        this.parRelativeTolerance = parRelativeTolerance;\n+        this.orthoTolerance = orthoTolerance;\n+    }\n+    /** {@inheritDoc} */\n+    @Override\n+    public PointVectorValuePair doOptimize() throws OptimizationException {\n+        // Reset counters for iteration and evaluation and set\n+        // flag to notify potential listeners that the algorithm has\n+        // started.\n+        iterations.incrementCount();\n+        // Obtain the cost function.\n+        final MultivariateVectorFunction objective = getObjectiveFunction();\n+        // Retrieve weight matrix (null means equal weights).\n+        final double[] targetValues = getTarget();\n+        final Weight weightMatrix = getWeight();\n+        // Get the initial guess as an ArrayRealVector.\n+        RealVector currentPoint = new ArrayRealVector(getStartPoint());\n+        // Determine the number of parameters.\n+        final int n = currentPoint.getDimension();\n+        // Compute the number of observations.\n+        final int m = targetValues.length;\n+        // Evaluate the model function and calculate the norm of the residuals.\n+        RealVector currentObjective = new ArrayRealVector(m);\n+        MatrixJacobian jacobian = new MatrixJacobian(m, n);\n+        updateResidualsAndCost(objective, currentPoint, currentObjective, jacobian, weightMatrix, targetValues);\n+        double currentCost = FastMath.sqrt(cost);\n+        // Create a point-value pair for the current iteration.\n+        PointVectorValuePair current = new PointVectorValuePair(currentPoint.toArray(), currentObjective.toArray());\n+        // Set up iteration counter and flag.\n+        int k = 0;\n+        boolean converged = false;\n+        // Outer loop.\n         lmPar = 0;\n-        boolean firstIteration = true;\n-        VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n-        while (true) {\n+        while (!converged) {\n             incrementIterationsCounter();\n-\n-            // compute the Q.R. decomposition of the jacobian matrix\n-            VectorialPointValuePair previous = current;\n-            updateJacobian();\n-            qrDecomposition();\n-\n-            // compute Qt.res\n-            qTy(residuals);\n-            // now we don't need Q anymore,\n-            // so let jacobian contain the R matrix with its diagonal elements\n-            for (int k = 0; k < solvedCols; ++k) {\n-                int pk = permutation[k];\n-                jacobian[k][pk] = diagR[pk];\n+            // Build the jacobian matrix.\n+            updateJacobian(objective, currentPoint, jacobian);\n+            // Build the weighted jacobian.\n+            weightedJacobian = WeightedJacobian.compute(jacobian.getJacobianMatrix(), weightMatrix);\n+            // Wrap the weighted jacobian in a matrix wrapper.\n+            RealMatrix jT = weightedJacobian.transpose();\n+            // Calculate JT * J.\n+            jTj = jT.multiply(weightedJacobian);\n+            // Now, add lambda to the diagonal elements of JTJ.\n+            // Recall that lambda is related to the damping factor via:\n+            // lambda = damping^2 * max(diagonal elements of JTJ).\n+            lmPar = getDampingFactor(lmPar, jTj);\n+            // Create a diagonal matrix from the diagonal elements of JTJ.\n+            diagR = new double[n];\n+            for (int i = 0; i < n; ++i) {\n+                diagR[i] = jTj.getEntry(i, i);\n             }\n-\n-            if (firstIteration) {\n-\n-                // scale the point according to the norms of the columns\n-                // of the initial jacobian\n-                xNorm = 0;\n-                for (int k = 0; k < cols; ++k) {\n-                    double dk = jacNorm[k];\n-                    if (dk == 0) {\n-                        dk = 1.0;\n-                    }\n-                    double xk = dk * point[k];\n-                    xNorm  += xk * xk;\n-                    diag[k] = dk;\n+            // Compute the Q.R. decomposition of the jacobian matrix.\n+            cachedJacobian = new QRDecomposition(weightedJacobian);\n+            final double[][] qrt = cachedJacobian.getR().getData();\n+            // Update the residuals.\n+            isJacobianUpdateRequired = true;\n+            if (k == 0) {\n+                // Scale the point according to the norms of the columns\n+                // of the initial jacobian.\n+                diag = new double[n];\n+                for (int j = 0; j < n; ++j) {\n+                    diag[j] = qrt[j][j];\n                 }\n-                xNorm = Math.sqrt(xNorm);\n-\n-                // initialize the step bound delta\n-                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n-\n-            }\n-\n-            // check orthogonality between function vector and jacobian columns\n-            double maxCosine = 0;\n-            if (cost != 0) {\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int    pj = permutation[j];\n-                    double s  = jacNorm[pj];\n-                    if (s != 0) {\n-                        double sum = 0;\n-                        for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * residuals[i];\n-                        }\n-                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n-                    }\n+                // Compute the norm of the scaled point.\n+                double xNorm = currentPoint.getNorm();\n+                double sgn = (currentPoint.dotProduct(currentObjective) >= 0) ? 1 : -1;\n+                double initialStepBound = FastMath.min(initialStepBoundFactor * xNorm, 1.0e-3);\n+                lmPar = 0;\n+                // The outer loop continues only if the relative reduction\n+                // in the objective function is not less than 0.1 percent.\n+                if ((FastMath.sqrt(sumSquares(currentObjective)) / targetValues.length) < 0.1 * currentCost) {\n+                    converged = true;\n                 }\n-            }\n-            if (maxCosine <= orthoTolerance) {\n-                // convergence has been reached\n-                return current;\n-            }\n-\n-            // rescale if necessary\n-            for (int j = 0; j < cols; ++j) {\n-                diag[j] = Math.max(diag[j], jacNorm[j]);\n-            }\n-\n-            // inner loop\n-            for (double ratio = 0; ratio < 1.0e-4;) {\n-\n-                // save the state\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    oldX[pj] = point[pj];\n-                }\n-                double previousCost = cost;\n-                double[] tmpVec = residuals;\n-                residuals = oldRes;\n-                oldRes    = tmpVec;\n-\n-                // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n-\n-                // compute the new point and the norm of the evolution direction\n-                double lmNorm = 0;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    lmDir[pj] = -lmDir[pj];\n-                    point[pj] = oldX[pj] + lmDir[pj];\n-                    double s = diag[pj] * lmDir[pj];\n-                    lmNorm  += s * s;\n-                }\n-                lmNorm = Math.sqrt(lmNorm);\n-                // on the first iteration, adjust the initial step bound.\n-                if (firstIteration) {\n-                    delta = Math.min(delta, lmNorm);\n-                }\n-\n-                // evaluate the function at x + p and calculate its norm\n-                updateResidualsAndCost();\n-                current = new VectorialPointValuePair(point, objective);\n-\n-                // compute the scaled actual reduction\n-                double actRed = -1.0;\n-                if (0.1 * cost < previousCost) {\n-                    double r = cost / previousCost;\n-                    actRed = 1.0 - r * r;\n-                }\n-\n-                // compute the scaled predicted reduction\n-                // and the scaled directional derivative\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    double dirJ = lmDir[pj];\n-                    work1[j] = 0;\n-                    for (int i = 0; i <= j; ++i) {\n-                        work1[i] += jacobian[i][pj] * dirJ;\n-                    }\n-                }\n-                double coeff1 = 0;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    coeff1 += work1[j] * work1[j];\n+            } else {\n+                // Diagonal elements of the residual covariance matrix\n+                // provide a measure of the scale of the uncertainties in\n+                // the parameter estimates. We'll use scaled variables\n+                // to better track such uncertainties.\n+                for (int j = 0; j < n; ++j) {\n+                    diag[j] = FastMath.sqrt(qrt[j][j]);\n                 }\n-                double pc2 = previousCost * previousCost;\n-                coeff1 = coeff1 / pc2;\n-                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n-                double preRed = coeff1 + 2 * coeff2;\n-                double dirDer = -(coeff1 + coeff2);\n-\n-                // ratio of the actual to the predicted reduction\n-                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n-\n-                // update the step bound\n-                if (ratio <= 0.25) {\n-                    double tmp =\n-                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n-                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n-                            tmp = 0.1;\n-                        }\n-                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n-                        lmPar /= tmp;\n-                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n-                    delta = 2 * lmNorm;\n-                    lmPar *= 0.5;\n-                }\n-\n-                // test for successful iteration.\n-                if (ratio >= 1.0e-4) {\n-                    // successful iteration, update the norm\n-                    firstIteration = false;\n-                    xNorm = 0;\n-                    for (int k = 0; k < cols; ++k) {\n-                        double xK = diag[k] * point[k];\n-                        xNorm    += xK * xK;\n-                    }\n-                    xNorm = Math.sqrt(xNorm);\n-\n-                    // tests for convergence.\n-                    // we use the vectorial convergence checker\n-                } else {\n-                    // failed iteration, reset the previous values\n-                    cost = previousCost;\n-                    for (int j = 0; j < solvedCols; ++j) {\n-                        int pj = permutation[j];\n-                        point[pj] = oldX[pj];\n-                    }\n-                    tmpVec    = residuals;\n-                    residuals = oldRes;\n-                    oldRes    = tmpVec;\n-                }\n-                if (checker==null) {\n-                \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n-                        (preRed <= costRelativeTolerance) &&\n-                        (ratio <= 2.0)) ||\n-                       (delta <= parRelativeTolerance * xNorm)) {\n-                       return current;\n-                   }\n-                } else {\n-                    if (checker.converged(getIterations(), previous, current)) {\n-                        return current;\n-                    }\n-                }\n-                // tests for termination and stringent tolerances\n-                // (2.2204e-16 is the machine epsilon for IEEE754)\n-                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n-                            costRelativeTolerance);\n-                } else if (delta <= 2.2204e-16 * xNorm) {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n-                            parRelativeTolerance);\n-                } else if (maxCosine <= 2.2204e-16)  {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n-                            orthoTolerance);\n-                }\n-\n-            }\n-\n-        }\n-\n-    }\n+                // Compute the norm of the current step.\n+                double xNorm = currentPoint.getNorm();\n+                double sgn = (currentPoint.dotProduct(currentObjective) >= 0) ? 1 : -1;\n+                double initialStepBound = FastMath.min(initialStepBoundFactor * xNorm, 1.0e-3);\n+                // The outer loop continues if the relative reduction in\n+                // the objective function is greater than the threshold tol.\n+                // Furthermore, if the step is small, convergence is determined.\n+                if ((FastMath.abs(sumSquares(currentObjective) - currentCost)) / currentCost < costRelativeTolerance) {\n+                    converged = true;\n+                } else if (parRelativeTolerance*sumSquares(currentPoint) < initialStepBound*EPSILON) {\n+                    converge\n \n     /**\n      * Determine the Levenberg-Marquardt parameter.",
    "result_reason": "error: illegal start of type",
    "test_result": "ERROR"
}