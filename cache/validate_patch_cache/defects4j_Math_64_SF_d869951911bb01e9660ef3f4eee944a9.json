{
    "patch": "protected VectorialPointValuePair doOptimize()\n\tthrows FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n\t// arrays shared with the other private methods\n\tsolvedCols  = Math.min(rows, cols);\n\tdiagR       = new double[cols];\n\tjacNorm     = new double[cols];\n\tbeta        = new double[cols];\n\tpermutation = new int[cols];\n\tlmDir       = new double[cols];\n\n\t// local point\n\tdouble   delta   = 0;\n\tdouble   xNorm   = 0;\n\tdouble[] diag    = new double[cols];\n\tdouble[] oldX    = new double[cols];\n\tdouble[] oldRes  = new double[rows];\n\tdouble[] work1   = new double[cols];\n\tdouble[] work2   = new double[cols];\n\tdouble[] work3   = new double[cols];\n\n\t// evaluate the function at the starting point and calculate its norm\n\tupdateResidualsAndCost();\n\n\t// outer loop\n\tlmPar = 0;\n\tboolean firstIteration = true;\n\tVectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n\twhile (true) {\n\t\tincrementIterationsCounter();\n\n\t\t// compute the Q.R. decomposition of the jacobian matrix\n\t\tVectorialPointValuePair previous = current;\n\t\tupdateJacobian();\n\t\tqrDecomposition();\n\n\t\t// compute Qt.res\n\t\tqTy(residuals);\n\t\t// now we don't need Q anymore,\n\t\t// so let jacobian contain the R matrix with its diagonal elements\n\t\tfor (int k = 0; k < solvedCols; ++k) {\n\t\t\tint pk = permutation[k];\n\t\t\tjacobian[k][pk] = diagR[pk];\n\t\t}\n\n\t\tif (firstIteration) {\n\t\t\t// scale the point according to the norms of the columns\n\t\t\t// of the initial jacobian\n\t\t\txNorm = 0;\n\t\t\tfor (int k = 0; k < cols; ++k) {\n\t\t\t\tdouble dk = jacNorm[k];\n\t\t\t\tif (dk == 0) {\n\t\t\t\t\tdk = 1.0;\n\t\t\t\t}\n\t\t\t\tdouble xk = dk * point[k];\n\t\t\t\txNorm  += xk * xk;\n\t\t\t\tdiag[k] = dk;\n\t\t\t}\n\t\t\txNorm = Math.sqrt(xNorm);\n\n\t\t\t// initialize the step bound delta\n\t\t\tdelta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n\t\t}\n\n\t\t// check orthogonality between function vector and jacobian columns\n\t\tdouble maxCosine = 0;\n\t\tif (cost != 0) {\n\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n\t\t\t\tint    pj = permutation[j];\n\t\t\t\tdouble s  = jacNorm[pj];\n\t\t\t\tif (s != 0) {\n\t\t\t\t\tdouble sum = 0;\n\t\t\t\t\tfor (int i = 0; i <= j; ++i) {\n\t\t\t\t\t\tsum += jacobian[i][pj] * residuals[i];\n\t\t\t\t\t}\n\t\t\t\t\tmaxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (maxCosine <= orthoTolerance) {\n\t\t\t// convergence has been reached\n\t\t\treturn current;\n\t\t}\n\n\t\t// rescale if necessary\n\t\tfor (int j = 0; j < cols; ++j) {\n\t\t\tdiag[j] = Math.max(diag[j], jacNorm[j]);\n\t\t}\n\n\t\t// inner loop\n\t\tfor (double ratio = 0; ratio < 1.0e-4;) {\n\n\t\t\t// save the state\n\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n\t\t\t\tint pj = permutation[j];\n\t\t\t\toldX[pj] = point[pj];\n\t\t\t}\n\t\t\tdouble previousCost = cost;\n\t\t\tdouble[] tmpVec = residuals;\n\t\t\tresiduals = oldRes;\n\t\t\toldRes    = tmpVec;\n\n\t\t\t// determine the Levenberg-Marquardt parameter\n\t\t\tdetermineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n\t\t\t// compute the new point and the norm of the evolution direction\n\t\t\tdouble lmNorm = 0;\n\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n\t\t\t\tint pj = permutation[j];\n\t\t\t\tlmDir[pj] = -lmDir[pj];\n\t\t\t\tpoint[pj] = oldX[pj] + lmDir[pj];\n\t\t\t\tdouble s = diag[pj] * lmDir[pj];\n\t\t\t\tlmNorm  += s * s;\n\t\t\t}\n\t\t\tlmNorm = Math.sqrt(lmNorm);\n\t\t\t// on the first iteration, adjust the initial step bound.\n\t\t\tif (firstIteration) {\n\t\t\t\tdelta = Math.min(delta, lmNorm);\n\t\t\t}\n\n\t\t\t// evaluate the function at x + p and calculate its norm\n\t\t\tupdateResidualsAndCost();\n\t\t\tcurrent = new VectorialPointValuePair(point, objective);\n\n\t\t\t// compute the scaled actual reduction\n\t\t\tdouble actRed = -1.0;\n\t\t\tif (0.1 * cost < previousCost) {\n\t\t\t\tdouble r = cost / previousCost;\n\t\t\t\tactRed = 1.0 - r * r;\n\t\t\t}\n\n\t\t\t// compute the scaled predicted reduction\n\t\t\t// and the scaled directional derivative\n\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n\t\t\t\tint pj = permutation[j];\n\t\t\t\tdouble dirJ = lmDir[pj];\n\t\t\t\twork1[j] = 0;\n\t\t\t\tfor (int i = 0; i <= j; ++i) {\n\t\t\t\t\twork1[i] += jacobian[i][pj] * dirJ;\n\t\t\t\t}\n\t\t\t}\n\t\t\tdouble coeff1 = 0;\n\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n\t\t\t\tcoeff1 += work1[j] * work1[j];\n\t\t\t}\n\t\t\tdouble pc2 = previousCost * previousCost;\n\t\t\tcoeff1 = coeff1 / pc2;\n\t\t\tdouble coeff2 = lmPar * lmNorm * lmNorm / pc2;\n\t\t\tdouble preRed = coeff1 + 2 * coeff2;\n\t\t\tdouble dirDer = -(coeff1 + coeff2);\n\n\t\t\t// ratio of the actual to the predicted reduction\n\t\t\tratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n\t\t\t// update the step bound\n\t\t\tif (ratio <= 0.25) {\n\t\t\t\tdouble tmp =\n\t\t\t\t\t(actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n\t\t\t\t\tif ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n\t\t\t\t\t\ttmp = 0.1;\n\t\t\t\t\t}\n\t\t\t\t\tdelta = tmp * Math.min(delta, 10.0 * lmNorm);\n\t\t\t\t\tlmPar /= tmp;\n\t\t\t} else if ((lmPar == 0) || (ratio >= 0.75)) {\n\t\t\t\t\tdelta = 2 * lmNorm;\n\t\t\t\t\tlmPar *= 0.5;\n\t\t\t}\n\n\t\t\t// test for successful iteration.\n\t\t\tif (ratio >= 1.0e-4) {\n\t\t\t\t// successful iteration, update the norm\n\t\t\t\tfirstIteration = false;\n\t\t\t\txNorm = 0;\n\t\t\t\tfor (int k = 0; k < cols; ++k) {\n\t\t\t\t\tdouble xK = diag[k] * point[k];\n\t\t\t\t\txNorm    += xK * xK;\n\t\t\t\t}\n\t\t\t\txNorm = Math.sqrt(xNorm);\n\n\t\t\t\t// tests for convergence.\n\t\t\t\t// we use the vectorial convergence checker\n\t\t\t} else {\n\t\t\t\t// failed iteration, reset the previous values\n\t\t\t\tcost = previousCost;\n\t\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n\t\t\t\t\tint pj = permutation[j];\n\t\t\t\t\tpoint[pj] = oldX[pj];\n\t\t\t\t}\n\t\t\t\ttmpVec    = residuals;\n\t\t\t\tresiduals = oldRes;\n\t\t\t\toldRes    = tmpVec;\n\t\t\t}\n\t\t\tif (checker==null) {\n\t\t\t\tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n\t\t\t\t\t(preRed <= costRelativeTolerance) &&\n\t\t\t\t\t(ratio <= 2.0)) ||\n\t\t\t\t   (delta <= parRelativeTolerance * xNorm)) {\n\t\t\t\t\treturn current;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (checker.converged(getIterations(), previous, current)) {\n\t\t\t\t\treturn current;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// tests for termination and stringent tolerances\n\t\t\t// (2.2204e-16 is the machine epsilon for IEEE754)\n\t\t\tif ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n\t\t\t\tthrow new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n\t\t\t\t\t\tcos",
    "patch_diff": "diff --git a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\nindex 50914932e..70a7c4801 100644\n--- a/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n+++ b/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java\n@@ -238,230 +238,216 @@ public class LevenbergMarquardtOptimizer extends AbstractLeastSquaresOptimizer {\n \n     /** {@inheritDoc} */\n     @Override\n-    protected VectorialPointValuePair doOptimize()\n-        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n-\n-        // arrays shared with the other private methods\n-        solvedCols  = Math.min(rows, cols);\n-        diagR       = new double[cols];\n-        jacNorm     = new double[cols];\n-        beta        = new double[cols];\n-        permutation = new int[cols];\n-        lmDir       = new double[cols];\n-\n-        // local point\n-        double   delta   = 0;\n-        double   xNorm   = 0;\n-        double[] diag    = new double[cols];\n-        double[] oldX    = new double[cols];\n-        double[] oldRes  = new double[rows];\n-        double[] work1   = new double[cols];\n-        double[] work2   = new double[cols];\n-        double[] work3   = new double[cols];\n-\n-        // evaluate the function at the starting point and calculate its norm\n-        updateResidualsAndCost();\n-\n-        // outer loop\n-        lmPar = 0;\n-        boolean firstIteration = true;\n-        VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n-        while (true) {\n-            incrementIterationsCounter();\n-\n-            // compute the Q.R. decomposition of the jacobian matrix\n-            VectorialPointValuePair previous = current;\n-            updateJacobian();\n-            qrDecomposition();\n-\n-            // compute Qt.res\n-            qTy(residuals);\n-            // now we don't need Q anymore,\n-            // so let jacobian contain the R matrix with its diagonal elements\n-            for (int k = 0; k < solvedCols; ++k) {\n-                int pk = permutation[k];\n-                jacobian[k][pk] = diagR[pk];\n-            }\n-\n-            if (firstIteration) {\n-\n-                // scale the point according to the norms of the columns\n-                // of the initial jacobian\n-                xNorm = 0;\n-                for (int k = 0; k < cols; ++k) {\n-                    double dk = jacNorm[k];\n-                    if (dk == 0) {\n-                        dk = 1.0;\n-                    }\n-                    double xk = dk * point[k];\n-                    xNorm  += xk * xk;\n-                    diag[k] = dk;\n-                }\n-                xNorm = Math.sqrt(xNorm);\n-\n-                // initialize the step bound delta\n-                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n-\n-            }\n-\n-            // check orthogonality between function vector and jacobian columns\n-            double maxCosine = 0;\n-            if (cost != 0) {\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int    pj = permutation[j];\n-                    double s  = jacNorm[pj];\n-                    if (s != 0) {\n-                        double sum = 0;\n-                        for (int i = 0; i <= j; ++i) {\n-                            sum += jacobian[i][pj] * residuals[i];\n-                        }\n-                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n-                    }\n-                }\n-            }\n-            if (maxCosine <= orthoTolerance) {\n-                // convergence has been reached\n-                return current;\n-            }\n-\n-            // rescale if necessary\n-            for (int j = 0; j < cols; ++j) {\n-                diag[j] = Math.max(diag[j], jacNorm[j]);\n-            }\n-\n-            // inner loop\n-            for (double ratio = 0; ratio < 1.0e-4;) {\n-\n-                // save the state\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    oldX[pj] = point[pj];\n-                }\n-                double previousCost = cost;\n-                double[] tmpVec = residuals;\n-                residuals = oldRes;\n-                oldRes    = tmpVec;\n-\n-                // determine the Levenberg-Marquardt parameter\n-                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n-\n-                // compute the new point and the norm of the evolution direction\n-                double lmNorm = 0;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    lmDir[pj] = -lmDir[pj];\n-                    point[pj] = oldX[pj] + lmDir[pj];\n-                    double s = diag[pj] * lmDir[pj];\n-                    lmNorm  += s * s;\n-                }\n-                lmNorm = Math.sqrt(lmNorm);\n-                // on the first iteration, adjust the initial step bound.\n-                if (firstIteration) {\n-                    delta = Math.min(delta, lmNorm);\n-                }\n-\n-                // evaluate the function at x + p and calculate its norm\n-                updateResidualsAndCost();\n-                current = new VectorialPointValuePair(point, objective);\n-\n-                // compute the scaled actual reduction\n-                double actRed = -1.0;\n-                if (0.1 * cost < previousCost) {\n-                    double r = cost / previousCost;\n-                    actRed = 1.0 - r * r;\n-                }\n-\n-                // compute the scaled predicted reduction\n-                // and the scaled directional derivative\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    double dirJ = lmDir[pj];\n-                    work1[j] = 0;\n-                    for (int i = 0; i <= j; ++i) {\n-                        work1[i] += jacobian[i][pj] * dirJ;\n-                    }\n-                }\n-                double coeff1 = 0;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    coeff1 += work1[j] * work1[j];\n-                }\n-                double pc2 = previousCost * previousCost;\n-                coeff1 = coeff1 / pc2;\n-                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n-                double preRed = coeff1 + 2 * coeff2;\n-                double dirDer = -(coeff1 + coeff2);\n-\n-                // ratio of the actual to the predicted reduction\n-                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n-\n-                // update the step bound\n-                if (ratio <= 0.25) {\n-                    double tmp =\n-                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n-                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n-                            tmp = 0.1;\n-                        }\n-                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n-                        lmPar /= tmp;\n-                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n-                    delta = 2 * lmNorm;\n-                    lmPar *= 0.5;\n-                }\n-\n-                // test for successful iteration.\n-                if (ratio >= 1.0e-4) {\n-                    // successful iteration, update the norm\n-                    firstIteration = false;\n-                    xNorm = 0;\n-                    for (int k = 0; k < cols; ++k) {\n-                        double xK = diag[k] * point[k];\n-                        xNorm    += xK * xK;\n-                    }\n-                    xNorm = Math.sqrt(xNorm);\n-\n-                    // tests for convergence.\n-                    // we use the vectorial convergence checker\n-                } else {\n-                    // failed iteration, reset the previous values\n-                    cost = previousCost;\n-                    for (int j = 0; j < solvedCols; ++j) {\n-                        int pj = permutation[j];\n-                        point[pj] = oldX[pj];\n-                    }\n-                    tmpVec    = residuals;\n-                    residuals = oldRes;\n-                    oldRes    = tmpVec;\n-                }\n-                if (checker==null) {\n-                \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n-                        (preRed <= costRelativeTolerance) &&\n-                        (ratio <= 2.0)) ||\n-                       (delta <= parRelativeTolerance * xNorm)) {\n-                       return current;\n-                   }\n-                } else {\n-                    if (checker.converged(getIterations(), previous, current)) {\n-                        return current;\n-                    }\n-                }\n-                // tests for termination and stringent tolerances\n-                // (2.2204e-16 is the machine epsilon for IEEE754)\n-                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n-                            costRelativeTolerance);\n-                } else if (delta <= 2.2204e-16 * xNorm) {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n-                            parRelativeTolerance);\n-                } else if (maxCosine <= 2.2204e-16)  {\n-                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n-                            orthoTolerance);\n-                }\n-\n-            }\n-\n-        }\n-\n-    }\n+protected VectorialPointValuePair doOptimize()\n+\tthrows FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n+\n+\t// arrays shared with the other private methods\n+\tsolvedCols  = Math.min(rows, cols);\n+\tdiagR       = new double[cols];\n+\tjacNorm     = new double[cols];\n+\tbeta        = new double[cols];\n+\tpermutation = new int[cols];\n+\tlmDir       = new double[cols];\n+\n+\t// local point\n+\tdouble   delta   = 0;\n+\tdouble   xNorm   = 0;\n+\tdouble[] diag    = new double[cols];\n+\tdouble[] oldX    = new double[cols];\n+\tdouble[] oldRes  = new double[rows];\n+\tdouble[] work1   = new double[cols];\n+\tdouble[] work2   = new double[cols];\n+\tdouble[] work3   = new double[cols];\n+\n+\t// evaluate the function at the starting point and calculate its norm\n+\tupdateResidualsAndCost();\n+\n+\t// outer loop\n+\tlmPar = 0;\n+\tboolean firstIteration = true;\n+\tVectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n+\twhile (true) {\n+\t\tincrementIterationsCounter();\n+\n+\t\t// compute the Q.R. decomposition of the jacobian matrix\n+\t\tVectorialPointValuePair previous = current;\n+\t\tupdateJacobian();\n+\t\tqrDecomposition();\n+\n+\t\t// compute Qt.res\n+\t\tqTy(residuals);\n+\t\t// now we don't need Q anymore,\n+\t\t// so let jacobian contain the R matrix with its diagonal elements\n+\t\tfor (int k = 0; k < solvedCols; ++k) {\n+\t\t\tint pk = permutation[k];\n+\t\t\tjacobian[k][pk] = diagR[pk];\n+\t\t}\n+\n+\t\tif (firstIteration) {\n+\t\t\t// scale the point according to the norms of the columns\n+\t\t\t// of the initial jacobian\n+\t\t\txNorm = 0;\n+\t\t\tfor (int k = 0; k < cols; ++k) {\n+\t\t\t\tdouble dk = jacNorm[k];\n+\t\t\t\tif (dk == 0) {\n+\t\t\t\t\tdk = 1.0;\n+\t\t\t\t}\n+\t\t\t\tdouble xk = dk * point[k];\n+\t\t\t\txNorm  += xk * xk;\n+\t\t\t\tdiag[k] = dk;\n+\t\t\t}\n+\t\t\txNorm = Math.sqrt(xNorm);\n+\n+\t\t\t// initialize the step bound delta\n+\t\t\tdelta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n+\n+\t\t}\n+\n+\t\t// check orthogonality between function vector and jacobian columns\n+\t\tdouble maxCosine = 0;\n+\t\tif (cost != 0) {\n+\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n+\t\t\t\tint    pj = permutation[j];\n+\t\t\t\tdouble s  = jacNorm[pj];\n+\t\t\t\tif (s != 0) {\n+\t\t\t\t\tdouble sum = 0;\n+\t\t\t\t\tfor (int i = 0; i <= j; ++i) {\n+\t\t\t\t\t\tsum += jacobian[i][pj] * residuals[i];\n+\t\t\t\t\t}\n+\t\t\t\t\tmaxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\tif (maxCosine <= orthoTolerance) {\n+\t\t\t// convergence has been reached\n+\t\t\treturn current;\n+\t\t}\n+\n+\t\t// rescale if necessary\n+\t\tfor (int j = 0; j < cols; ++j) {\n+\t\t\tdiag[j] = Math.max(diag[j], jacNorm[j]);\n+\t\t}\n+\n+\t\t// inner loop\n+\t\tfor (double ratio = 0; ratio < 1.0e-4;) {\n+\n+\t\t\t// save the state\n+\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n+\t\t\t\tint pj = permutation[j];\n+\t\t\t\toldX[pj] = point[pj];\n+\t\t\t}\n+\t\t\tdouble previousCost = cost;\n+\t\t\tdouble[] tmpVec = residuals;\n+\t\t\tresiduals = oldRes;\n+\t\t\toldRes    = tmpVec;\n+\n+\t\t\t// determine the Levenberg-Marquardt parameter\n+\t\t\tdetermineLMParameter(oldRes, delta, diag, work1, work2, work3);\n+\n+\t\t\t// compute the new point and the norm of the evolution direction\n+\t\t\tdouble lmNorm = 0;\n+\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n+\t\t\t\tint pj = permutation[j];\n+\t\t\t\tlmDir[pj] = -lmDir[pj];\n+\t\t\t\tpoint[pj] = oldX[pj] + lmDir[pj];\n+\t\t\t\tdouble s = diag[pj] * lmDir[pj];\n+\t\t\t\tlmNorm  += s * s;\n+\t\t\t}\n+\t\t\tlmNorm = Math.sqrt(lmNorm);\n+\t\t\t// on the first iteration, adjust the initial step bound.\n+\t\t\tif (firstIteration) {\n+\t\t\t\tdelta = Math.min(delta, lmNorm);\n+\t\t\t}\n+\n+\t\t\t// evaluate the function at x + p and calculate its norm\n+\t\t\tupdateResidualsAndCost();\n+\t\t\tcurrent = new VectorialPointValuePair(point, objective);\n+\n+\t\t\t// compute the scaled actual reduction\n+\t\t\tdouble actRed = -1.0;\n+\t\t\tif (0.1 * cost < previousCost) {\n+\t\t\t\tdouble r = cost / previousCost;\n+\t\t\t\tactRed = 1.0 - r * r;\n+\t\t\t}\n+\n+\t\t\t// compute the scaled predicted reduction\n+\t\t\t// and the scaled directional derivative\n+\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n+\t\t\t\tint pj = permutation[j];\n+\t\t\t\tdouble dirJ = lmDir[pj];\n+\t\t\t\twork1[j] = 0;\n+\t\t\t\tfor (int i = 0; i <= j; ++i) {\n+\t\t\t\t\twork1[i] += jacobian[i][pj] * dirJ;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tdouble coeff1 = 0;\n+\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n+\t\t\t\tcoeff1 += work1[j] * work1[j];\n+\t\t\t}\n+\t\t\tdouble pc2 = previousCost * previousCost;\n+\t\t\tcoeff1 = coeff1 / pc2;\n+\t\t\tdouble coeff2 = lmPar * lmNorm * lmNorm / pc2;\n+\t\t\tdouble preRed = coeff1 + 2 * coeff2;\n+\t\t\tdouble dirDer = -(coeff1 + coeff2);\n+\n+\t\t\t// ratio of the actual to the predicted reduction\n+\t\t\tratio = (preRed == 0) ? 0 : (actRed / preRed);\n+\n+\t\t\t// update the step bound\n+\t\t\tif (ratio <= 0.25) {\n+\t\t\t\tdouble tmp =\n+\t\t\t\t\t(actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n+\t\t\t\t\tif ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n+\t\t\t\t\t\ttmp = 0.1;\n+\t\t\t\t\t}\n+\t\t\t\t\tdelta = tmp * Math.min(delta, 10.0 * lmNorm);\n+\t\t\t\t\tlmPar /= tmp;\n+\t\t\t} else if ((lmPar == 0) || (ratio >= 0.75)) {\n+\t\t\t\t\tdelta = 2 * lmNorm;\n+\t\t\t\t\tlmPar *= 0.5;\n+\t\t\t}\n+\n+\t\t\t// test for successful iteration.\n+\t\t\tif (ratio >= 1.0e-4) {\n+\t\t\t\t// successful iteration, update the norm\n+\t\t\t\tfirstIteration = false;\n+\t\t\t\txNorm = 0;\n+\t\t\t\tfor (int k = 0; k < cols; ++k) {\n+\t\t\t\t\tdouble xK = diag[k] * point[k];\n+\t\t\t\t\txNorm    += xK * xK;\n+\t\t\t\t}\n+\t\t\t\txNorm = Math.sqrt(xNorm);\n+\n+\t\t\t\t// tests for convergence.\n+\t\t\t\t// we use the vectorial convergence checker\n+\t\t\t} else {\n+\t\t\t\t// failed iteration, reset the previous values\n+\t\t\t\tcost = previousCost;\n+\t\t\t\tfor (int j = 0; j < solvedCols; ++j) {\n+\t\t\t\t\tint pj = permutation[j];\n+\t\t\t\t\tpoint[pj] = oldX[pj];\n+\t\t\t\t}\n+\t\t\t\ttmpVec    = residuals;\n+\t\t\t\tresiduals = oldRes;\n+\t\t\t\toldRes    = tmpVec;\n+\t\t\t}\n+\t\t\tif (checker==null) {\n+\t\t\t\tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n+\t\t\t\t\t(preRed <= costRelativeTolerance) &&\n+\t\t\t\t\t(ratio <= 2.0)) ||\n+\t\t\t\t   (delta <= parRelativeTolerance * xNorm)) {\n+\t\t\t\t\treturn current;\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\tif (checker.converged(getIterations(), previous, current)) {\n+\t\t\t\t\treturn current;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\t// tests for termination and stringent tolerances\n+\t\t\t// (2.2204e-16 is the machine epsilon for IEEE754)\n+\t\t\tif ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n+\t\t\t\tthrow new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n+\t\t\t\t\t\tcos\n \n     /**\n      * Determine the Levenberg-Marquardt parameter.",
    "result_reason": "error: ')' expected",
    "test_result": "ERROR"
}